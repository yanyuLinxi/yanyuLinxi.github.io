<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>Batchnorm讲解 - 阳阳的人间旅游日记</title><meta name=keywords content="博客,程序员,思考,读书,笔记,技术,分享"><meta name=author content="阳阳"><meta property="og:title" content="Batchnorm讲解"><meta property="og:site_name" content="阳阳的人间旅游日记"><meta property="og:image" content="/img/author.jpg"><meta name=title content="Batchnorm讲解 - 阳阳的人间旅游日记"><meta name=description content="欢迎来到临溪的博客站，个人主要专注于机器学习、深度学习的相关研究。在这里分享自己的学习心得。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i><a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span><span class=site-title>阳阳的人间旅游日记</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>让我们消除隔阂的，不是无所不知的脑袋，而是手拉手，坚决不放弃的那颗心</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span><span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://yanyulinxi.github.io/post/study/deeplearning/batchnorm%E8%AE%B2%E8%A7%A3/ itemprop=url>Batchnorm讲解</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i><span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2021-11-22">2021-11-22</time></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i><span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>2189 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i><span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>5分钟</span></span>
<span id=/post/study/deeplearning/batchnorm%E8%AE%B2%E8%A7%A3/ class=leancloud_visitors data-flag-title=Batchnorm讲解>|
<i class="fa fa-binoculars fa-fw"></i><span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><h1 id=引用>引用</h1><p><a href=https://mp.weixin.qq.com/s/QFpolIXvOQjUsPAngqvqmg>https://mp.weixin.qq.com/s/QFpolIXvOQjUsPAngqvqmg</a></p><p>论文：
Correct Normalization Matters: Understanding the Effect of Normalization On Deep Neural Network Models For Click-Through Rate Prediction：https://arxiv.org/pdf/2006.12753.pdf</p><h1 id=介绍>介绍</h1><p><strong>谷歌</strong>在2015年就提出了<strong>Batch Normalization(BN)</strong>，该方法对每个mini-batch都进行normalize，会把mini-batch中的数据正规化到均值为0，标准差为1，同时<strong>还引入了两个可以学的参数</strong>，分别为scale和shift，让模型学习其适合的分布。</p><p><strong>那么为什么在做过正规化后，又要scale和shift呢？</strong>
因为scale和shift是模型自动学习的，神经网络可以自己琢磨前面的正规化有没有起到优化作用，没有的话就"反"正规化，抵消之前的正规化操作带来的影响。</p><p>让特征分布有一定的自由度，可以调整到对下一层更好的分布。</p><p>BatchNormalization是对一批样本进行处理, 对一批样本的每个特征分别进行归一化</p><p><strong>LayerNormalization</strong>是对一个样本进行处理，对一个样本的所有特征进行归一化，乍一看很没有道理，因为如果对身高体重和年龄一起求一个均值方差，都不知道这些值有什么含义，但存在一些场景却非常有效果——<strong>NLP领域</strong>。 在NLP中，N个特征都可能表示不同的词，这个时候我们仍然采用BatchNormalization的话，对第一个词进行操作，很显然意义就不是非常大了，因为任何一个词都可以放在第一个位置，而且很多时候词序对于我们对于句子的影响没那么大，而此时我们对N个词进行Normalization等操作可以很好地反映句子的分布。(LN一般用在第三维度，[batchsize, seq_len,dims])，因为该维度特征的量纲是相同的，所以并没有太多区别。</p><h1 id=为什么要用normalization>为什么要用Normalization？</h1><ol><li><p>解决梯度消失
拿sigmoid激活函数距离，从图中，我们很容易知道，数据值越靠近0梯度越大，越远离0梯度越接近0，<strong>我们通过BN改变数据分布到0附近</strong>，从而解决梯度消失问题。</p></li><li><p>解决了ICS internal Covariate Shift.
由于训练过程中参数的变化，每一层的更新，导致上层的输入数据分布发生巨大变化，每一次高层需要重新学习去适应新的分布。神经网络就要学习<strong>新的分布</strong>，随着层数的加深，学习过程就变的愈加困难，<strong>要解决这个问题需要使用较低的学习率，由此又产生收敛速度慢</strong>，因此引入BN可以很有效的解决这个问题。数据分布变化很大</p></li><li><p>加速了模型收敛速度。</p></li></ol><p>和对原始特征做归一化类似，BN使得每一维数据对结果的影响是相同的，由此就能加速模型的收敛速度。</p><ol start=4><li>引入了部分噪声。提升了泛化能力。</li></ol><h1 id=解析>解析</h1><p>我们发现 Normalization有效的最大一个原因在于方差的影响而不是均值。</p><h2 id=特征embedding上加入normalization是否有效>特征Embedding上加入Normalization是否有效？</h2><p>从上面的实验中,我们发现,在特征Embedding层加入Normalization都是有效的,而且LayerNorm以及相关的变种是效果相对稳定以及最好的;</p><h2 id=normalization公式>normalization公式：</h2><p>$\frac{x-\mu}{\theta}$, $\theta$是标准差。减去平均值除以标准差。</p><p>$$y = \frac { x - E [ x ] } { \sqrt {Var [ x ] + \xi } } * \gamma + \beta$$</p><h2 id=问题>问题：</h2><ol><li>Batch Norm的描述：<ol><li>该方法对每个mini-batch都进行normalize，会把mini-batch中的数据正规化到均值为0，标准差为1，同时还引入了两个可以学的参数，分别为scale和shift，让模型学习其适合的分布。</li></ol></li><li>Normalization的优点：<ol><li>四条：<ol><li>梯度消失</li><li>加快网络训练</li><li>引入噪声，提高泛化</li><li>解决ICS（内部协变量偏移问题）<ol><li>为什么引入噪声能提升泛化？加入噪声可以认为是在增加网络训练的难度，可以达到一定的正则效果。提升模型的鲁棒能力。</li></ol></li></ol></li><li>缺点：1. 当Batch小的时候，均值和方差不稳定</li></ol></li><li>和归一化的不同<ol><li>BatchNormalization层和正规化/归一化不同，BatchNormalization层是在mini-batch中计算均值方差，因此会带来一些较小的噪声，在神经网络中添加随机噪声可以带来正则化的效果。</li></ol></li><li>batchnorm一般放在那里<ol><li>一般放在线性层乘以权重参数后，放在激活函数前。</li><li>BN是为了让输入进入激活函数的非饱和区，所以这样效果更好。</li></ol></li><li>为什么在做过正规化后，又要scale和shift呢<ol><li>将分布拉扯到均值0，方差1附近，会丧失部分激活函数的非线性功能。比如sigmoid。所以添加scale和shift来偏移它们</li><li>normalization相当于把上一层作出的努力磨平了，神经网络 可以自己琢磨前面的正规化W有没有起到优化作用，没有的话就"反"正规化，抵消之前的正规化操作带来的影响。</li></ol></li><li>给定一个张量[N, C, W]，batchnorm，和layernorm分别在哪层做归一化<ol><li>画出图，认出哪个是一个样本，batchnorm就是对所有样本的一个维度做。layernorm对一个样本做</li><li>batch norm: N, W<ol><li>$\gamma, \beta$大小为c</li></ol></li><li>layer norm：C, W</li></ol></li><li>layernorm<ol><li><strong>LayerNormalization</strong>是对一个样本进行处理，对一个样本的所有特征进行归一化，乍一看很没有道理，因为如果对身高体重和年龄一起求一个均值方差，</li><li>而此时我们对N个词进行Normalization等操作可以很好地反映句子的分布。</li><li>nlp使用layernorm的理由<ol><li>bn不适用：1. 第一个位置是什么词都可以。2. 句子长度不一致</li><li>layernorm的优点：可以很好的反映句子的分布。</li></ol></li></ol></li></ol></div><footer class=post-footer><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>Batchnorm讲解</p><p style=word-break:break-all><span>链接：</span>
https://yanyulinxi.github.io/post/study/deeplearning/batchnorm%E8%AE%B2%E8%A7%A3/</p><p><span>作者：</span>阳阳</p><p><span>邮箱：</span>yanyulinxi@qq.com</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick="var qr=document.getElementById('QR');qr.style.display==='none'?qr.style.display='block':qr.style.display='none'">
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/-%E5%85%B6%E4%BB%96%E6%89%80%E6%9C%89%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E7%9A%84%E4%B9%A6%E7%B1%8D%E8%B5%84%E6%96%99/ rel=next title=-其他推荐书籍资料><i class="fa fa-chevron-left"></i>-其他推荐书籍资料</a></div><div class="post-nav-prev post-nav-item"><a href=https://yanyulinxi.github.io/post/paperreading/simclr-a-simple-framework-for-contrastive-learning-of-visual-representations/ rel=prev title="SimCLR a Simple Framework for Contrastive Learning of Visual Representations">SimCLR a Simple Framework for Contrastive Learning of Visual Representations
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/linxi_icon.png alt=阳阳><p class=site-author-name itemprop=name>阳阳</p><p class="site-description motion-element" itemprop=description>再平凡的人也有属于他自己的梦想!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>124</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>33</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/yanyuLinxi target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>GitHub</a></span>
<span class=links-of-author-item><a href=https://space.bilibili.com/19237450 target=_blank title=哔哩哔哩><i class="fa fa-fw fa-globe"></i>哔哩哔哩</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0>论文阅读笔记</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90>异常行为分析</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python%E7%9B%B8%E5%85%B3%E5%BA%93%E5%AD%A6%E4%B9%A0>Python相关库学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7>深度学习辅助工具</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%BA%93>机器学习相关库</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/java%E5%AD%A6%E4%B9%A0>Java学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/insider-threat>Insider threat</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/leetcode%E5%AD%A6%E4%B9%A0>Leetcode学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E7%BE%8E%E9%A3%9F%E7%82%B9%E8%AF%84>美食点评</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/rnn>Rnn</a></li></ul></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span><span class=copyright-author>阳阳的人间旅游日记</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.81.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv><i class="fa fa-user"></i><span class=busuanzi-value id=busuanzi_value_site_uv></span></span><span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i><span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href style=font-weight:700 target=_blank></a></span><span class=separator-line>/</span>
<span class=license-num><a href target=_blank></a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i><span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript src=/js/search.js></script><script type=text/javascript src=/js/affix.js></script><script type=text/javascript src=/js/scrollspy.js></script><script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script><script type=text/javascript>$(function(){$('.post-body').viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script><script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script></body></html>