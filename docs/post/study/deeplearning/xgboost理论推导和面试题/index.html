<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>XGBoost理论推导和面试题 - 阳阳的人间旅游日记</title><meta name=keywords content="博客,程序员,思考,读书,笔记,技术,分享"><meta name=author content="阳阳"><meta property="og:title" content="XGBoost理论推导和面试题"><meta property="og:site_name" content="阳阳的人间旅游日记"><meta property="og:image" content="/img/author.jpg"><meta name=title content="XGBoost理论推导和面试题 - 阳阳的人间旅游日记"><meta name=description content="欢迎来到临溪的博客站，个人主要专注于机器学习、深度学习的相关研究。在这里分享自己的学习心得。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i><a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span><span class=site-title>阳阳的人间旅游日记</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>让我们消除隔阂的，不是无所不知的脑袋，而是手拉手，坚决不放弃的那颗心</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span><span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://yanyulinxi.github.io/post/study/deeplearning/xgboost%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/ itemprop=url>XGBoost理论推导和面试题</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i><span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2022-02-17">2022-02-17</time></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i><span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>2513 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i><span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>6分钟</span></span>
<span id=/post/study/deeplearning/xgboost%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/ class=leancloud_visitors data-flag-title=XGBoost理论推导和面试题>|
<i class="fa fa-binoculars fa-fw"></i><span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><p>停止增长的条件：</p><ol><li>叶子节点的分裂gain&lt;=0</li><li>叶子节点只有一个样本的时候，就没必要划分了。</li><li>限制叶子节点个数</li></ol><p>计算出叶子节点的b_j。计算完后叶子节点的权重就为b_j</p><p>步骤：
1.</p><p>公式：https://zhuanlan.zhihu.com/p/46683728</p><ol><li>$$f ( x ) = \sum _ { j = 1 } ^ { J } b _ { j } I ( x \in R _ { j } )$$</li><li>将所有的样本加起来可以表示为：
$$\sum _ { i = 1 } ^ { N } f ( x _ { i } ) = \sum _ { j = 1 } ^ { J } \sum _ { x\in R_j} b _ { j }$$</li><li>所以公式推导为：
$$L ^ { m } = \sum _ { i = 1 } ^ { N } [g _ { i } f _ { m } ( x _ { i } ) + \frac { 1 } { 2 } h _ { i } f_m^2 ( x _ { i } )] + \gamma J + \frac { 1 } { 2 } \lambda \sum_{j=1}^Jb_j^2$$</li></ol><p>xgboost的训练方式和gbdt类似。计算m-1 f(x)的损失函数在训练样本点的一阶导、二阶导。然后用来分裂每个节点，生成树。最后加到模型中去f_{m-1}(x)+f_m(x)。再计算损失函数，拟合下一个。</p><h1 id=优化>优化</h1><p>优化思路：1. 压缩特征数（列采样） 2. 压缩每个特征下，特征的种类数（即特征的分裂点的数量）</p><ol><li>预防过拟合<ol><li>正则化</li><li>限制节点数量</li><li>限制Gain的增长。当Gain &lt; gamma则不分裂</li><li>列采样。随机采样特征<ol><li>按树随机。每一颗树筛选出来特征采样后，一整颗树的特征都不变</li><li>按层随机。每一层叶子节点分裂时，都进行采样。</li></ol></li><li>shrinkage 学习率<ol><li>加入学习率到基学习器中。$y=y_{m-1}+\eta f(x)$</li><li>有助于防止过拟合。一般取0.1.</li></ol></li></ol></li><li>速度优化：<ol><li>近似分裂算法：<ol><li>使用二阶导代替样本的权重，然后根据权重划分桶。设定一个值$\epsilon$,每个桶的权重值和应该小于$\epsilon$。会得到$\frac{1}{\epsilon}$个切分点。</li><li>为什么使用二阶导？二阶导可以看成是样本的权重。同时二阶导越大，说明该值附近变换越快，越应该进行切分。</li><li>和采样类似。有全局策略和局部策略。<ol><li>全局策略。第一次计算得到的分裂点，后面的分裂只会用这几个分裂点。</li><li>局部策略。每次分裂节点时，都会重新计算分裂点。优点是可以根据节点中的样本数计算分裂点。</li></ol></li></ol></li><li>系统设计<ol><li>核外块运算：<ol><li>块拆分。将不能存储在内存的数据放在磁盘中。并且拆分成块，以提高磁盘IO率。</li><li>块压缩。每个块存储时会压缩存储。读取时解压读取。</li><li>开启线程在运算数据的同时对数据进行读取。</li></ol></li><li>分块并行。<ol><li>预先对所有的特征进行按列预排序，并存储索引。这样每次分裂只需要一次线性扫描就能获得最大的Gain</li><li>分布式运行：将所有的特征分成N各块，发送给各个机器执行。最后将执行结果返回给调度中心。</li></ol></li><li>缓存命中率优化。由于特征存储为block结构。所以访问不是顺序访问的。为此在block后面开一个buffer，存储他们的一阶导和二阶导。直接读取一阶导和二阶导。这样命中率就会提高。</li></ol></li></ol></li><li>对缺失值的处理：<ol><li>所有的计算对非缺失值进行计算。计算完成后，缺失值整体放入左右，计算增益。设置最大增益方向为缺省（默认）方向放入缺失值。</li><li>预测中遇到缺失值，默认放入右节点。</li></ol></li></ol><h1 id=题目>题目</h1><p>参考：https://mp.weixin.qq.com/s?__biz=MzI1MzY0MzE4Mg==&mid=2247485159&idx=1&sn=d429aac8370ca5127e1e786995d4e8ec&chksm=e9d01626dea79f30043ab80652c4a859760c1ebc0d602e58e13490bf525ad7608a9610495b3d&scene=21#wechat_redirect</p><p><a href=https://github.com/datawhalechina/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/machine-learning/XGBoost.md>https://github.com/datawhalechina/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/machine-learning/XGBoost.md</a></p><ol><li><p>xgboost优缺点：</p><ol><li>XGBoost是大规模、分布式的通用梯度提升(GBDT)库。它是一个加法模型，每次迭代都学习一棵CART树来拟合之前 t-1 棵树的预测结果与训练样本真实值的残差。XGBoost对GBDT进行了一系列优化，比如损失函数进行了二阶泰勒展开、目标函数加入正则项、支持并行、默认缺失值处理等，在可扩展性和训练速度上有了巨大的提升，但其核心思想没有大的变化。</li><li>优点：<ol><li>精度更高、灵活性更好（不同的基分类器，不同的损失函数）、正则化、缺失值、训练速度快（可并行）</li></ol></li><li>缺点<ol><li>和lgbm相比，节点分裂过程中需要遍历所有特征</li><li>存储空间消耗较大。</li></ol></li></ol></li><li><p>XGBoost特征重要性。</p><ol><li>三种方式判断特征重要性。</li><li>freq：特定的特征在模型树种发生分裂的次数的百分比</li><li>gain：平均增益。特征在所有树种作为分裂节点的信息增益之和除以该特征出现的频次。</li><li>cover：节点样本的二阶导数和处理特征出现的频次。平均二阶导数和。二阶导和越大，说明该节点对方向做出了较多的指导。</li><li>xgboost一般采用gain。</li></ol></li><li><p>介绍一下XGB，怎么调参防止过拟合</p><ol><li>决策树方面：<ol><li>决策树节点最小样本权重和的阈值（这里指的是二阶导，官网api这么定义的）</li><li>树的最大深度</li><li>树节点的分裂阈值（增益阈值）</li></ol></li><li>公式<ol><li>正则化。目标函数添加正则化项。调整正则化系数</li><li>调整学习率 shrinkage</li></ol></li><li>数据方面：<ol><li>子采样</li><li>列抽样</li></ol></li></ol><p>第一类参数：用于直接控制模型的复杂度。包括max_depth，min_child_weight，gamma 等参数
第二类参数：用于增加随机性，从而使得模型在训练时对于噪音不敏感。包括subsample，colsample_by树
还有就是直接减小learning rate，但需要同时增加estimator 参数。</p></li><li><p>比较LR和GBDT，说说什么情景下GBDT不如LR</p><ol><li>在特征高维稀疏的情况下。逻辑回归线性模型控制权重。xgboost正则化控制树的大小。此时xboost只需要一个节点就能分类所有样本。正则化的作用很小。但是逻辑回归的正则化就不容易过拟合</li></ol></li><li><p>xgboost如何选择分裂点</p><ol><li>对特征值进行排序，存储为block结构。方便重复使用</li><li>使用近似分裂算法，根据样本的二阶导选择常数个分裂点。</li><li>采用特征并行的方法利用多个线程分别计算每个特征的最佳分裂点。进行分裂。</li></ol></li><li><p>xgboost缺失值</p><ol><li>默认使用不缺失的样本进行分裂</li><li>缺失样本整体放入左右节点，最大增益节点就为默认的分裂方向</li><li>预测值中出现没见过的缺失值，则放入右节点</li></ol></li><li><p>xgboost不平衡数据</p><ol><li>为正负样本设置不同权重。scale_pos_weight参数</li></ol></li><li><p>xgboost 为什么快？</p><ol><li>四点</li><li>特征预排序+block缓存，多线程并行</li><li>核外块运算</li><li>近似分裂算法</li><li>命中缓存优化</li></ol></li></ol></div><footer class=post-footer><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>XGBoost理论推导和面试题</p><p style=word-break:break-all><span>链接：</span>
https://yanyulinxi.github.io/post/study/deeplearning/xgboost%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/</p><p><span>作者：</span>阳阳</p><p><span>邮箱：</span>yanyulinxi@qq.com</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick="var qr=document.getElementById('QR');qr.style.display==='none'?qr.style.display='block':qr.style.display='none'">
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/%E5%86%B3%E7%AD%96%E6%A0%91%E8%AE%B2%E8%A7%A3%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/ rel=next title=决策树讲解和面试题><i class="fa fa-chevron-left"></i>决策树讲解和面试题</a></div><div class="post-nav-prev post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/gbdt%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/ rel=prev title=GBDT理论推导和面试题>GBDT理论推导和面试题
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/linxi_icon.png alt=阳阳><p class=site-author-name itemprop=name>阳阳</p><p class="site-description motion-element" itemprop=description>再平凡的人也有属于他自己的梦想!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>125</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>34</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/yanyuLinxi target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>GitHub</a></span>
<span class=links-of-author-item><a href=https://space.bilibili.com/19237450 target=_blank title=哔哩哔哩><i class="fa fa-fw fa-globe"></i>哔哩哔哩</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0>论文阅读笔记</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90>异常行为分析</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python%E7%9B%B8%E5%85%B3%E5%BA%93%E5%AD%A6%E4%B9%A0>Python相关库学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7>深度学习辅助工具</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%BA%93>机器学习相关库</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/java%E5%AD%A6%E4%B9%A0>Java学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/insider-threat>Insider threat</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/leetcode%E5%AD%A6%E4%B9%A0>Leetcode学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E7%BE%8E%E9%A3%9F%E7%82%B9%E8%AF%84>美食点评</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/rnn>Rnn</a></li></ul></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span><span class=copyright-author>阳阳的人间旅游日记</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.81.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv><i class="fa fa-user"></i><span class=busuanzi-value id=busuanzi_value_site_uv></span></span><span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i><span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href style=font-weight:700 target=_blank></a></span><span class=separator-line>/</span>
<span class=license-num><a href target=_blank></a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i><span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript src=/js/search.js></script><script type=text/javascript src=/js/affix.js></script><script type=text/javascript src=/js/scrollspy.js></script><script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script><script type=text/javascript>$(function(){$('.post-body').viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script><script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script></body></html>