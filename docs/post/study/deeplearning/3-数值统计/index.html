<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>3 数值统计 - 阳阳的人间旅游日记</title><meta name=keywords content="博客,程序员,思考,读书,笔记,技术,分享"><meta name=author content="阳阳"><meta property="og:title" content="3 数值统计"><meta property="og:site_name" content="阳阳的人间旅游日记"><meta property="og:image" content="/img/author.jpg"><meta name=title content="3 数值统计 - 阳阳的人间旅游日记"><meta name=description content="欢迎来到临溪的博客站，个人主要专注于机器学习、深度学习的相关研究。在这里分享自己的学习心得。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i><a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span><span class=site-title>阳阳的人间旅游日记</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>让我们消除隔阂的，不是无所不知的脑袋，而是手拉手，坚决不放弃的那颗心</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span><span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://yanyulinxi.github.io/post/study/deeplearning/3-%E6%95%B0%E5%80%BC%E7%BB%9F%E8%AE%A1/ itemprop=url>3 数值统计</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i><span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2021-11-09">2021-11-09</time></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i><span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>4049 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i><span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>9分钟</span></span>
<span id=/post/study/deeplearning/3-%E6%95%B0%E5%80%BC%E7%BB%9F%E8%AE%A1/ class=leancloud_visitors data-flag-title="3 数值统计">|
<i class="fa fa-binoculars fa-fw"></i><span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><p>机器学习算法通常需要大量的数值计算。这通常是指通过<strong>迭代过程更新解的估 计值来解决数学问题的算法</strong>，而不是通过解析过程推导出公式来提供正确解的方法</p><h1 id=上溢下溢>上溢下溢</h1><ol><li><strong>连续数学在数字计算机上的根本困难</strong>是，我们需要通过有限数量的位模式来<strong>表 示无限多的实数</strong>。意味着我们在计算机中表示实数时，几乎总会引入一些<strong>近似误 差。</strong></li><li>一种极具毁灭性的舍入误差是<strong>下溢（underflow）</strong>。当接近零的数被四舍五入为 零时发生下溢。</li><li>另一个极具破坏力的数值错误形式是<strong>上溢（overflow）</strong>。当大量级的数被近似为 ∞ 或 −∞ 时发生上溢。进一步的运算通常会导致这些无限值变为非数字。</li><li>上溢和下溢进行数值稳定的一个例子是softmax 函数</li><li>Theano (Bergstra et al., 2010a; Bastien et al., 2012a) 就是这样软件包的一个例子，它能自动检测并稳定深度学习中许多常见的数值不稳定的表达式。</li></ol><h1 id=病态条件>病态条件</h1><ol><li>考虑函数 f(x) = A−1x。当 A ∈ Rn×n 具有特征值分解时，其条件数为$max_{i,j} |\frac{\lambda_i}{\lambda_j}|$。这是最大和最小特征值的模之比1。当**该数很大**时，矩阵求逆对输入的**误差特别敏感**。</li></ol><h1 id=基于梯度的优化方法>基于梯度的优化方法</h1><ol><li><p>我们把要最小化或最大化的函数称为<strong>目标函数（objective function）<strong>或</strong>准则 （criterion）</strong>。</p><ol><li>当我们对其进行最小化时，我们也把它称为<strong>代价函数（cost function）</strong>、<strong>损失函数（loss function）<strong>或</strong>误差函数（error function）。</strong></li><li>我们通常使用一个<strong>上标 ∗</strong>表示最小化或最大化函数的 x 值。如我们记 x∗ = arg min f(x)。</li></ol></li><li><p>这个函数的导数（derivative） 记为 f′(x) 或 dy/dx。导数 f′(x) 代表 f(x) 在点 x 处的斜率。</p></li><li><p>因此<strong>导数</strong>对于最小化一个函数很有用，因为它告诉我们如何更改 x 来略微地改 善 y。这种技术被称为<strong>梯度下降</strong> （gradient descent）(Cauchy, 1847)。</p></li><li><p>f′(x) = 0 的点称为<strong>临界 点</strong>（critical point）或驻点（stationary point）。</p><ol><li>f′(x) = 0 的点称为<strong>临界 点</strong>（critical point）或<strong>驻点</strong>（stationary point）。</li><li>f′(x) = 0 的点称为<strong>临界 点</strong>（critical point）或<strong>驻点</strong>（stationary point）。</li><li>有些临界点既不是最小点也不是最大点。这些点被称为<strong>鞍点</strong>（saddle point）。</li></ol></li><li><p>因此，我们通常寻找使 f 非常小的 点，但这在任何形式意义下并不一定是最小。</p></li><li><p>我们需要用到<strong>偏导数</strong>（partial derivative）的概念</p></li><li><p>**梯度（gradient）**是相对一个向量求导的导数:f 的导数是包含所有偏导数的向量，记为 ∇xf(x)。梯度的第i 个元素是 f 关于 xi 的偏导数。</p></li><li><p>在 u（单位向量）方向的<strong>方向导数</strong>（directional derivative）是函数 f 在 u 方向 的斜率。</p></li><li><p>负梯度向量指向下坡。我们在负梯度方向上移动可以减小 f。这被称为<strong>最速下降法</strong> (method of steepest descent) 或<strong>梯度下降</strong>（gradient descent）。</p></li><li><p>最速下降建议新的点为 x′ = x− ϵ∇xf(x) (4.5)其中 ϵ 为<strong>学习率</strong>（learning rate），是一个确定步长大小的正标量</p><ol><li>最速下降在梯度的每一个元素为零时收敛（或在实践中，很接近零时）</li><li>但不断向更好的情况移动一小 步（即近似最佳的小移动）的一般概念可以推广到离散空间。递增带有离散参数的目标函数被称为<strong>爬山</strong>（hill climbing）算法 (Russel and Norvig, 2003)</li></ol></li><li><p>有时我们需要计算输入和输出都为向量的函数的所有偏导数。包含所有这样的 偏导数的矩阵被称为 <strong>Jacobian 矩阵</strong></p><ol><li>二阶导数告诉我们，一阶导数将如何随着输入 的变化而改变。它表示只基于梯度信息的梯度下降步骤是否会产生如我们预期的那样大的改善，因此它是重要的。我们可以认为，二阶导数是对曲率的衡量</li><li>如果这样的函数具有零二阶导数，那就没有曲率。也就是一条完全 平坦的线，仅用梯度就可以预测它的值。我们使用沿负梯度方向大小为 ϵ 的下降步， 当该梯度是 1 时，代价函数将下降 ϵ。如果二阶导数是负的，函数曲线向下凹陷 (向 上凸出)，因此代价函数将下降的比 ϵ 多。如果二阶导数是正的，函数曲线是向上凹陷 (向下凸出)，因此代价函数将下降的比 ϵ 少</li></ol></li><li><p>当我们的函数具有多维输入时，二阶导数也有很多。我们可以将这些导数合并 成一个矩阵，称为 <strong>Hessian 矩阵</strong></p></li><li><p>Hessian <strong>等价于</strong>梯度的 Jacobian 矩阵。</p></li><li><p>微分算子在任何二阶偏导连续的点处可交换，也就是它们的顺序可以互换：这意味着 Hi,j = Hj,i，因此 Hessian 矩阵在这些点上是对称的。因为 Hessian 矩阵是实对 称的，我们可以将其分解成一组实特征值和一组特征向量的正交基。在特定方向 d上的二阶导数可以写成 d⊤Hd。这个方向的二阶导 数就是对应的特征值。对于其他的方向 d，方向二阶导数是所有特征值的加权平均， 权重在 0 和 1 之间，且与 d 夹角越小的特征向量的权重越大。最大特征值确定最大二阶导数，最小特征值确定最小二阶导数。</p><ol><li>Hessian 的特征值决定了<strong>学 习率的量级</strong></li></ol></li><li><p>当 f′(x) = 0 且 f′′(x) > 0 时，x 是一个<strong>局 部极小点</strong>。同样，当 f′(x) = 0 且 f′′(x) &lt; 0 时，x 是一个<strong>局部极大点</strong>。这就是所谓的<strong>二阶导数测试（second derivative test）。</strong></p></li><li><p>在临界点处（∇xf(x) = 0），我们通 <strong>过检测 Hessian 的特征值来判断该临界点是一个局部极大点、局部极小点还是鞍点。</strong> 当 Hessian 是<strong>正定</strong>的（所有特征值都是正的），则该临界点是<strong>局部极小点</strong>。因为方 向二阶导数在任意方向都是正的，参考单变量的二阶导数测试就能得出此结论。同 样的，当 Hessian 是<strong>负定的</strong>（所有特征值都是负的），这个点就是<strong>局部极大点</strong>。在多 维情况下，实际上我们可以找到确定该点是否为鞍点的积极迹象（某些情况下）。如 果 Hessian 的特征值中<strong>至少一个是正的且至少一个是负的</strong>，那么 x 是 f <strong>某个横截面 的局部极大点</strong>，却是<strong>另一个横截面的局部极小点</strong>。见图4.5中的例子。最后，多维二 阶导数测试可能像单变量版本那样是不确定的。<strong>当所有非零特征值是同号的且至少 有一个特征值是 0 时</strong>，这个检测就是<strong>不确定的</strong>。这是因为单变量的二阶导数测试在<strong>零特征值对应的横截面上是不确定的。</strong></p></li><li><p>维度多于一个时，鞍点不一定要具有 0 特征值：仅需要同时具有正特征值和负特征值。我 们可以想象这样一个鞍点（具有正负特征值）在一个<strong>横截面内是局部极大</strong>点，而在另一个<strong>横截面内是局部极小点。</strong></p></li><li><p>中期稍微总结一下：</p><ol><li>jacobian矩阵是梯度矩阵，表明了下一步权重下降的方向。Hessian衡量梯度下降的速率。如果hessian值正定，则权重是局部极小点。如果hessian负定，则权重是局部极大点。当涉及多维的时候条件更苛刻一点。有非零特征值时，这个检测是不确定的。根据梯度下降的方向进行下降，就是梯度下降。证明需要看书。大约就是二阶导，高中学的那一套。</li></ol></li><li><p>在<strong>多维情况下</strong>，单个点在每个方向上的二阶导数时不同的，Hessian 的条件数衡量 这些二阶导数的变化范围。<strong>当 Hessian 的条件数很差时</strong>，梯度下降法也会表现得很差。<strong>这是因为一个方向上的导数增加得很快，而在另一个方向上增加得很慢</strong>。</p><ol><li>梯度下降把时间浪费于在峡谷壁反复下 降，因为它们是最陡峭的特征。由于步长有点大，有超过函数底部的趋势，因此需要在下一次迭代时在对面的峡谷壁下降</li></ol></li><li><p>我们可以使用 <strong>Hessian 矩阵的信息</strong>来指导搜索，以解决这个问题。其中最简单 的方法是<strong>牛顿法</strong>（Newton’s method）。</p><ol><li>当 f 是一个正定二次函数时，牛顿法只要应用一次式(4.12)就能直接跳到函数的最 小点。如果 f 不是一个真正二次但能在局部近似为正定二次，牛顿法则需要多次迭代应用式。</li><li>如式(8.2.3)所讨论的，当附近的临界点是最小点（Hessian 的所有特征值 都是正的）时牛顿法才适用，而梯度下降不会被吸引到鞍点(除非梯度指向鞍点)。</li></ol></li><li><p>仅使用梯度信息的优化算法被称为<strong>一阶优化算法</strong> (first-order optimization algorithms)，<strong>如梯度下降</strong>。使用 <strong>Hessian 矩阵的优化算法被称为二阶最优化算法</strong>(second-order optimization algorithms)(Nocedal and Wright, 2006)，<strong>如牛顿法</strong></p></li><li><p>在深度学习的背景下，限制<strong>函数满足Lipschitz 连续</strong>（Lipschitz continuous）或 其导数Lipschitz连续可以获得一些保证。最成功的特定优化领域或许是<strong>凸优化</strong>（Convex optimization）。凸优化通过更强 的限制提供更多的保证。凸优化算法只对凸函数适用，即 Hessian 处处半正定的函数。</p></li></ol><h1 id=约束优化>约束优化</h1><ol><li>在 x 的所有可能值下最大化或最小化一个函数 f(x) 不是我们所希望 的。相反，我们可能希望在 x 的某些集合 S 中找 f(x) 的最大值或最小值。这被称为<strong>约束优化</strong>（constrained optimization）。集合 S 内的点 x 被称可行（feasible）点。</li><li>我们常常希望找到在<strong>某种意义上小的解。</strong></li><li>约束优化的一个简单方法是将约束考虑在内后简单地对梯度下降进行修改。<ol><li>如 果我们**使用一个小的恒定步长 ϵ，**我们可以先取梯度下降的单步结果，然后将结果投影回 S。</li><li>如果我们使用线搜索，我们只能在<strong>步长为 ϵ 范围内搜索</strong>可行的新 x 点</li><li>或者 我们可以将线上的<strong>每个点投影到约束区域</strong>。</li><li>在梯度下降或线搜索前 将梯度投影到可行域的切空间会更高效 (Rosen, 1960)。</li></ol></li><li>一个更复杂的方法是设计一个不同的、无约束的优化问题，其解可以转化成原 始约束优化问题的解**Karush–Kuhn–Tucker（KKT）**方法2是针对约束优化非常通用的解决方案。</li><li>我们引入一个称为<strong>广义 Lagrangian</strong>（generalized Lagrangian） 或<strong>广义 Lagrange 函数</strong>（generalized Lagrange function）的新函数。</li><li>那么 S 可以表示为 S = {x | ∀i, g(i)(x) = 0 and ∀j, h(j)(x) ≤ 0}。其中涉及 g(i) 的等式称为等式约束（equality constraint），涉及 h(j) 的不等式称为不等式约束（inequality constraint）。<ol><li>这是因为当约束满足时，广义lagrangian函数的值为f(x)的值。</li><li>当约束不满足时，广义lagrangian为无穷大。</li></ol></li><li>我们可以使用一组简单的性质来描述约束优化问题的最优点。这些性质称 为Karush–Kuhn–Tucker（KKT）条件<ol><li>广义 Lagrangian 的梯度为零</li><li>所有关于 x 和 KKT 乘子的约束都满足。</li><li>不等式约束显示的 ‘‘互补松弛性’’：α⊙ h(x) = 0。</li></ol></li></ol><h1 id=实例分析线性最小二乘法>实例分析：线性最小二乘法</h1><p>没看懂</p></div><footer class=post-footer><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>3 数值统计</p><p style=word-break:break-all><span>链接：</span>
https://yanyulinxi.github.io/post/study/deeplearning/3-%E6%95%B0%E5%80%BC%E7%BB%9F%E8%AE%A1/</p><p><span>作者：</span>阳阳</p><p><span>邮箱：</span>yanyulinxi@qq.com</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick="var qr=document.getElementById('QR');qr.style.display==='none'?qr.style.display='block':qr.style.display='none'">
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/ rel=next title="4 机器学习基础"><i class="fa fa-chevron-left"></i>4 机器学习基础</a></div><div class="post-nav-prev post-nav-item"><a href=https://yanyulinxi.github.io/post/study/server%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E5%85%B3/mysql/mysql_21mins_tutorial/ rel=prev title=Mysql_21mins_tutorial>Mysql_21mins_tutorial
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/linxi_icon.png alt=阳阳><p class=site-author-name itemprop=name>阳阳</p><p class="site-description motion-element" itemprop=description>再平凡的人也有属于他自己的梦想!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>129</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>34</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/yanyuLinxi target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>GitHub</a></span>
<span class=links-of-author-item><a href=https://space.bilibili.com/19237450 target=_blank title=哔哩哔哩><i class="fa fa-fw fa-globe"></i>哔哩哔哩</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0>论文阅读笔记</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90>异常行为分析</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python%E7%9B%B8%E5%85%B3%E5%BA%93%E5%AD%A6%E4%B9%A0>Python相关库学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7>深度学习辅助工具</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%BA%93>机器学习相关库</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/java%E5%AD%A6%E4%B9%A0>Java学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/insider-threat>Insider threat</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/leetcode%E5%AD%A6%E4%B9%A0>Leetcode学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E7%BE%8E%E9%A3%9F%E7%82%B9%E8%AF%84>美食点评</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/rnn>Rnn</a></li></ul></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span><span class=copyright-author>阳阳的人间旅游日记</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.81.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv><i class="fa fa-user"></i><span class=busuanzi-value id=busuanzi_value_site_uv></span></span><span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i><span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href style=font-weight:700 target=_blank></a></span><span class=separator-line>/</span>
<span class=license-num><a href target=_blank></a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i><span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript src=/js/search.js></script><script type=text/javascript src=/js/affix.js></script><script type=text/javascript src=/js/scrollspy.js></script><script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script><script type=text/javascript>$(function(){$('.post-body').viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script><script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script></body></html>