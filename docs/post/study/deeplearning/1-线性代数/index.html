<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>线性代数 - 阳阳的人间旅游日记</title><meta name=keywords content="博客,程序员,思考,读书,笔记,技术,分享"><meta name=author content="阳阳"><meta property="og:title" content="线性代数"><meta property="og:site_name" content="阳阳的人间旅游日记"><meta property="og:image" content="/img/author.jpg"><meta name=title content="线性代数 - 阳阳的人间旅游日记"><meta name=description content="欢迎来到临溪的博客站，个人主要专注于机器学习、深度学习的相关研究。在这里分享自己的学习心得。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i><a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span><span class=site-title>阳阳的人间旅游日记</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>让我们消除隔阂的，不是无所不知的脑袋，而是手拉手，坚决不放弃的那颗心</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span><span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://yanyulinxi.github.io/post/study/deeplearning/1-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/ itemprop=url>线性代数</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i><span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2021-10-19">2021-10-19</time></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i><span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>3026 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i><span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>7分钟</span></span>
<span id=/post/study/deeplearning/1-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/ class=leancloud_visitors data-flag-title=线性代数>|
<i class="fa fa-binoculars fa-fw"></i><span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><ul><li><a href=#%E5%B8%B8%E8%A7%81%E6%A6%82%E5%BF%B5>常见概念</a><ul><li><a href=#%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3>特征分解</a></li><li><a href=#%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3>奇异值分解</a></li></ul></li></ul><h1 id=常见概念>常见概念</h1><p>标量
向量
矩阵
张量</p><ol><li><p>矩阵加法：C = A + b。表示向量b和矩阵的每一行相加。这种隐式复制的方式，称为广播。boardcasting</p></li><li><p>元素对应乘积： A $\odot$ B hadamard 乘积</p></li><li><p>由一组解线性组合而成的解称为 <em><strong>生成子空间</strong></em>。表示原始向量线性组合后能抵达的点的集合。</p></li><li><p>矩阵列向量线性相关的矩阵，称为<em><strong>奇异</strong></em>的。</p></li><li><p><em><strong>范数</strong></em>： 形式上 $L^p 定义为 ||x||_p = (\sum_i|x_i|^p)^{\frac{1}{p}}$ 。
满足的性质：</p><ol><li>$f(x) = 0 -> x=0$</li><li>$f(x+y) \leq f(x) + f(y)$ (三角不等式)</li><li>$\forall \alpha \in R, f(\alpha x) = |\alpha|f(x)$</li></ol></li><li><p>当p=2的时候，$L^2$就是<em><strong>欧几里得范数</strong></em>。表示从原点到x确定的点的欧几里得距离。经常表示为$||x||$。平方$L^2$范数对x中每个元素的导数取决于对应的元素。而$L^2$范数对每个元素的导数却和整个向量相关。但是平方L2范数在原点附近增长的十分缓慢。L1范数在0附近增长则正相关。</p></li><li><p><em><strong>最大范数</strong></em>$L^{\infty} => ||x||_\infty = max|x_i|$</p></li><li><p><em><strong>Frobenius范数</strong></em>，衡量矩阵的大小。</p></li></ol><h2 id=特征分解>特征分解</h2><ol start=9><li><p>***对角矩阵（diagonal matrix）***只在主对角线上含有非零元素，其他位置都是零。我们用 diag(v) 表示一个对角元素 由向量 v 中元素给定的对角方阵。计算乘法 diag(v)x，我们只需要将 x 中的每个元素 xi 放大 vi 倍。换 言之，diag(v)x = v⊙ x</p><ol><li>对角方阵的逆矩阵存在， 当且仅当对角元素都是非零值</li><li>但通过将一些矩阵限制为对角矩阵，我们可以得到计算代价较低的（并且简明扼要的）算法</li></ol></li><li><p><em><strong>对称（symmetric）矩阵</strong></em>是转置和自己相等的矩阵</p></li><li><p><em><strong>单位向量</strong></em>（unit vector）是具有单位范数（unit norm）的向量：$||x||_2 = 1$.</p></li><li><p>如果 x⊤y = 0，那么向量 x 和向量 y 互相正交（orthogonal）。如果这些向量不仅互相正交，并且范数都为 1，那么我们称它们 是标准正交（orthonormal）。</p><ol><li>正交矩阵（orthogonal matrix）是指行向量和列向量是分别标准正交的方阵, 这意味着$A^{−1} = A^⊤$</li></ol></li><li><p><em><strong>特征分解（eigendecomposition</strong></em>）是使用最广的矩阵分解之一，即我们将矩阵分 解成一组特征向量和特征值.方阵 <em><strong>A 的特征向量</strong></em>（eigenvector）是指与 A 相乘后相当于对该向量进行缩放 的非零向量 v:$Av=\lambda v$.标量 λ 被称为这个特征向量对应的特征值（eigenvalue）</p><ol><li>每个实对称矩阵都可以分解成实特征向量和实特征值</li><li>按照惯例，我们通常按降序排列 Λ 的元素。在该 约定下，特征分解唯一当且仅当所有的特征值都是唯一的。</li></ol></li><li><p>矩阵是奇异的当且仅当含 有零特征值</p></li><li><p>所有特征值都是正数的矩阵被称为正定（positive definite）；所有特征值都是非 负数的矩阵被称为半正定（positive semidefinite）。半正定矩阵受到关注是因为它们保证 ∀x, x⊤Ax ≥ 0。此外， 正定矩阵还保证 x⊤Ax = 0 ⇒ x = 0。</p></li></ol><h2 id=奇异值分解>奇异值分解</h2><ol start=16><li><p>被称为<em><strong>奇异值分解</strong></em>（singular value decomposition, SVD），将矩阵分 解为奇异向量（singular vector）和<em><strong>奇异值</strong></em>（singular value）。每 个实数矩阵都有一个奇异值分解，但不一定都有特征分解。</p></li><li><p>对角矩阵 D 对角线上的元素被称为矩阵 A 的奇异值（singular value）。矩阵 U的列向量被称为左奇异向量（left singular vector），矩阵 V的列向量被称右奇异向量（right singular vector）。 事实上，我们可以用与 A 相关的特征分解去解释 A 的奇异值分解。A 的左奇 异向量（left singular vector）是AA⊤ 的特征向量。A的右奇异向量（right singular vector）是 A⊤A 的特征向量。A 的非零奇异值是 A⊤A 特征值的平方根，同时也是
AA⊤ 特征值的平方根。</p></li><li><p>奇异值分解是类似的，只不过这回我们将矩阵 A 分解成三个矩阵的乘积$A = UDV^⊤$.矩阵 U和 V都定义为正交 矩阵，而矩阵 D 定义为对角矩阵。注意，矩阵 D 不一定是方阵。A 的奇异值（singular value）。矩阵 U的列向量被称为左奇异向量（left singular vector），矩阵 V的列向量被称右奇异
向量（right singular vector）。<em><strong>SVD最有用的一个性质可能是拓展矩阵求逆到非方矩阵上。</strong></em></p></li><li><p><em><strong>Moore-Penrose 伪逆</strong></em>. 当矩阵 A 的列数多于行数时，使用伪逆求解线性方程是众多可能解法中的一 种。特别地，x = A+y 是方程所有可行解中欧几里得范数 ∥x∥2 最小的一个。当矩阵 A 的行数多于列数时，可能没有解。在这种情况下，通过伪逆得到的 x 使得 Ax 和 y 的欧几里得距离 ∥Ax− y∥2 最小。</p></li><li><p><em><strong>迹运算</strong></em>返回的是矩阵对角元素的和.多个矩阵相乘得到的方阵的迹，和将这些矩阵中的最后一个挪到最前面之后相 乘的迹是相同的。</p></li><li><p><em><strong>行列式，记作 det(A)</strong></em>，如果行列式是 0，那么空间至少沿着某一维完全收缩了，使其失去了所有的 体积。如果行列式是 1，那么这个转换保持空间体积不变。</p></li><li><p>***主成分分析（principal components analysis, PCA）***是一个简单的机器学习算 法，可以通过基础的线性代数知识推导。对于每个点 x(i) ∈ Rn，会有一个对应的 编码向量 c(i) ∈ Rl。如果 l 比 n 小，那么我们便使用了更少的内存来存储原来的数据。f(x) = c；我们也希望找到一 个解码函数，给定编码重构输入，x ≈ g(f(x))。了简化解码器，我们使用矩阵乘 法将编码映射回 Rn，即 g(c) = Dc，其中 D ∈ Rn×l 是定义解码的矩阵。</p><ol><li>目前为止所描述的问题，可能会有多个解. 为了使问 题有唯一解，我们限制 D 中所有列向量都有单位范数</li><li>首先我们需要明确如何根据每 一个输入 x 得到一个最优编码 c∗。一种方法是最小化原始输入向量 x 和重构向量 g(c∗) 之间的距离。我们使用范数来衡量它们之间的距离。在PCA算法中，我们使用 L2 范数：</li><li>我们可以用平方 L2 范数替代 L2 范数，因为两者在相同的值 c 上取得最小值。这是因为 L2 范数是非负的，并且平方运算在非负值上是单调递增的。</li><li>这使得算法很高效：最优编码 x 只需要一个矩阵-向量乘法操作。为了编码向量， 我们使用编码函数$f(x) = D^⊤x$.进一步使用矩阵乘法，我们也可以定义PCA重构操作：r(x) = g(f(x)) = DD⊤x.</li><li>具体来讲，最优的 d 是 X⊤X最大特 征值对应的特征向量。以上推导特定于 l = 1 的情况，仅得到了第一个主成分。更一般地，当我们希望 得到主成分的基时，矩阵 D 由前 l 个最大的特征值对应的特征向量组成。这个结论 可以通过归纳法证明，我们建议将此证明作为练习。</li><li><em><strong>从线性代数的角度总结</strong></em>：PCA是最小化压缩后的矩阵和原始矩阵之间的距离。通常使用平方$L^2$范数来表示这个距离。经过在一维的运算，最优的d是$X^TX$最大特征值对应的特征向量。通过归纳法得知压缩矩阵D由前l个最大的特征直对应的特征向量组成。</li><li>从其他角度还有更广泛的解释：</li><li>方差：表示数据的分散程度。协方差表示两个变量的相关性。</li><li>思想方法：<ol><li>将坐标轴移动到数据的中心，旋转坐标轴，使得数据在c1轴上的方差最大，即<strong>全部n个数据个体在该方向投影最分散</strong>。C1为第一主成分。</li><li>找一个C2，使得C2和C1的协方差（相关系数）为0，上市的数据在该方向的方差尽量最大。</li><li>依次类推。</li></ol></li><li>数学方法：<ol><li>将原始数据按列组成 n 行 m 列矩阵 X</li><li>将 X 的每一行进行零均值化，即减去这一行的均值；</li><li>求出<strong>协方差矩阵</strong></li><li>求出协方差矩阵的<strong>特征值及对应的特征向量；</strong></li><li>将<strong>特征向量按对应特征值大小从上到下按行排列成矩阵，取前 k 行组成矩阵 P；</strong></li><li>即为降维到 k 维后的数据。</li></ol></li><li>优缺点：<ol><li>保留了主要信息。<strong>这个主要信息未必是重要信息</strong>。很可能是非主要信息取了决定性作用。</li><li>起到了<strong>降噪降维的作用</strong>。且PCA后的<strong>特征相互独立。</strong></li></ol></li><li>补充。方差，表示数据的分散程度。</li><li>协方差理解为一致性分散程度有多大。在分散程度的相关性有多大。协方差为0，分散程度不相关。</li></ol></li><li></li></ol></div><footer class=post-footer><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>线性代数</p><p style=word-break:break-all><span>链接：</span>
https://yanyulinxi.github.io/post/study/deeplearning/1-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</p><p><span>作者：</span>阳阳</p><p><span>邮箱：</span>yanyulinxi@qq.com</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick="var qr=document.getElementById('QR');qr.style.display==='none'?qr.style.display='block':qr.style.display='none'">
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/0-%E5%BC%95%E8%A8%80%E5%92%8C%E7%AC%A6%E5%8F%B7%E8%A1%A8/ rel=next title="0 引言"><i class="fa fa-chevron-left"></i>0 引言</a></div><div class="post-nav-prev post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/%E6%BA%90%E4%BB%A3%E7%A0%81%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E8%AF%86%E5%88%AB/ rel=prev title=源代码恶意代码识别>源代码恶意代码识别
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/linxi_icon.png alt=阳阳><p class=site-author-name itemprop=name>阳阳</p><p class="site-description motion-element" itemprop=description>再平凡的人也有属于他自己的梦想!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>139</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>35</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/yanyuLinxi target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>GitHub</a></span>
<span class=links-of-author-item><a href=https://space.bilibili.com/19237450 target=_blank title=哔哩哔哩><i class="fa fa-fw fa-globe"></i>哔哩哔哩</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0>论文阅读笔记</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python%E7%9B%B8%E5%85%B3%E5%BA%93%E5%AD%A6%E4%B9%A0>Python相关库学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90>异常行为分析</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7>深度学习辅助工具</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%BA%93>机器学习相关库</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/kaggle>Kaggle</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/java%E5%AD%A6%E4%B9%A0>Java学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/insider-threat>Insider threat</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/leetcode%E5%AD%A6%E4%B9%A0>Leetcode学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/spark>Spark</a></li></ul></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span><span class=copyright-author>阳阳的人间旅游日记</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.81.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv><i class="fa fa-user"></i><span class=busuanzi-value id=busuanzi_value_site_uv></span></span><span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i><span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href style=font-weight:700 target=_blank></a></span><span class=separator-line>/</span>
<span class=license-num><a href target=_blank></a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i><span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript src=/js/search.js></script><script type=text/javascript src=/js/affix.js></script><script type=text/javascript src=/js/scrollspy.js></script><script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script><script type=text/javascript>$(function(){$('.post-body').viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script><script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script></body></html>