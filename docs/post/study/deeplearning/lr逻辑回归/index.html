<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>逻辑回归lr - 阳阳的人间旅游日记</title><meta name=keywords content="博客,程序员,思考,读书,笔记,技术,分享"><meta name=author content="阳阳"><meta property="og:title" content="逻辑回归lr"><meta property="og:site_name" content="阳阳的人间旅游日记"><meta property="og:image" content="/img/author.jpg"><meta name=title content="逻辑回归lr - 阳阳的人间旅游日记"><meta name=description content="欢迎来到临溪的博客站，个人主要专注于机器学习、深度学习的相关研究。在这里分享自己的学习心得。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i><a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span><span class=site-title>阳阳的人间旅游日记</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>让我们消除隔阂的，不是无所不知的脑袋，而是手拉手，坚决不放弃的那颗心</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span><span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://yanyulinxi.github.io/post/study/deeplearning/lr%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/ itemprop=url>逻辑回归lr</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i><span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2021-12-11">2021-12-11</time></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i><span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>3829 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i><span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>8分钟</span></span>
<span id=/post/study/deeplearning/lr%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/ class=leancloud_visitors data-flag-title=逻辑回归lr>|
<i class="fa fa-binoculars fa-fw"></i><span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><p>逻辑回归
个人理解 y = f(wx+b)
f 为 sigmoid激活函数 $1/(1+e^{-z})$</p><p>公式推导:
<a href=https://zhuanlan.zhihu.com/p/44591359>https://zhuanlan.zhihu.com/p/44591359</a>
<a href=https://zhuanlan.zhihu.com/p/46928319>https://zhuanlan.zhihu.com/p/46928319</a></p><h1 id=极大似然估计>极大似然估计</h1><ol><li>概率<ol><li>在知道<strong>分布规律</strong>和<strong>具体参数</strong>的情况下，可以计算出某个事件发生的概率。</li><li>举例：抛硬币10次，5次正面朝上的概率。分布规律为二项分布。参数为正面朝上的概率为1/2。随意概率为$c^5_{10}*0.5^5*(1-0.5)^5=0.25$</li></ol></li><li>估计<ol><li>不知道分布规律和具体参数，进行猜测。即为估计。</li></ol></li><li>极大似然估计<ol><li>似然函数（联合概率）公式：将多个概率值相乘。$L=\prod_{i=1}^n p{x=k_i|p}$，k_i为事件。P_k为概率。</li><li>优化目标：$\hat{p}=argmax_p L$. 求一个参数使得出现现有样本可能性最大。</li><li>方法：取对数 $lnL$然后拟牛顿法，或者梯度下降。</li></ol></li><li>步骤：<ol><li>确定分布/模型</li><li>进行多组实验并观察客观现象</li><li>写出似然概率（联合概率）</li><li>求解似然函数最大的凸优化问题，求的参数（梯度下降）</li></ol></li></ol><h1 id=梯度下降>梯度下降</h1><ol><li>原理：将参数沿着梯度相反的方向前进一个步长，就可以实现目标函数（loss function）的下降。</li><li>方法：<ol><li>使用损失函数，对每个参数（变量）求偏导数</li><li>将值带入，求下降方向$J(\theta)$</li><li>根据步长$\alpha$，进行一步梯度下降 $\theta &lt;= \theta-\alpha J(\theta)$</li></ol></li></ol><h1 id=交叉熵损失>交叉熵损失</h1><ol><li>公式$f(w)=-\frac{1}{m}\sum_{i=1}^N(y^ilogf_w(x^i)+(1-y^i)log(1-x^i))$</li><li>推导：<ol><li>对于每一个样本，设它为1的概率为p，则为0的概率为1-p</li><li>即
$$
P(y|x)=
\begin{cases}
p& \text{y=1}\<br>1-p& \text{y=0}
\end{cases}
$$</li><li>上述式子不方便计算。其等价于$p(y_i|x_i)=p^{y_i}(1-p)^{1-y_i}$。 即当$y_i=1$时，该值为p,否则为1-p</li><li>其最大似然估计为$L=\prod_{i=1}^n p^{y_n}(1-p)^{1-y_n}$。在逻辑回归中，这里面只有一个参数就在p里面。</li><li>上个式子不好计算，所以我们取对数$F ( w ) = \ln ( P _ { 总} ) \= \ln ( \prod _ { n = 1 } ^ { N } p ^ { y _ { n } }( 1 - p ) ^ { 1 - y _ { n } } ) \= \sum _ { n = 1 } ^ { N } ( y _ { n } \ln ( p ) + ( 1 - y _ { n } ) \ln ( 1 - p ) )$。 最终为求使得这个值最大的w。添加一个符号即为求最小值。即可以用梯度下降。</li></ol></li><li>注意：在使用softmax归一化后，极大似然函数和交叉熵损失函数等价。</li><li>凸函数判定：二阶导存在且为正。则为凸函数。凸函数意思是在凸集中局部最优等于全局最优。<ol><li>二阶导存在且为正，则一阶导有负有正，则原函数局部最小就是全局最小。</li></ol></li></ol><h1 id=线性回归>线性回归</h1><ol><li><p>线性回归(Linear Regression)是利用称为线性回归方程对线性问题进行建模。
公式：$f ( x ) = \theta _ { 0 } x _ { 0 } + \theta _ { 1 } x _ { 1 } + \theta _ { 2 } x _ { 2 }+&mldr; + \theta _ { n } x _ { n } = \theta ^ { T }$</p></li><li><p>损失函数。</p><ol><li>损失函数一般使用最小二乘法。$MSE=\frac{1}{2m} \sum(y-f(x))^2$</li></ol></li><li><p>Lasso回归</p><ol><li>目的：解决线性回归出现的过拟合的请况。本质：约束(限制)要优化的参数</li><li>Lasso回归加入L1正则化（$\lambda$*绝对值和)</li></ol></li><li><p>岭回归加入L2正则化$\lambda$*平方和。</p></li><li><p>ElasticNet 回归：$\lambda(pL1+(1-p)L2)$</p></li><li><p>LWR( 局部加权)回归:</p><ol><li>局部加权线性回归是在线性回归的基础上对每一个测试样本（训练的时候就是每一个训练样本）在其已有的样本进行一个加权拟合，权重的确定可以通过一个核来计算，常用的有高斯核（离测试样本越近，权重越大，反之越小）</li><li>具体的查资料</li></ol></li></ol><h2 id=面试题>面试题：</h2><ol><li>线性回归要求因变量服从正态分布吗<ol><li>前提假设是因变量服从正态分布，此时效果达到最好。</li></ol></li></ol><h1 id=公式推导>公式推导</h1><ol><li>背景知识<ol><li><strong>回归</strong>：人们在测量事物的时候因为客观条件所限，求得的都是测量值，而不是事物真实的值，为了能够得到真实值，<strong>无限次的进行测量</strong>，最后通过这些测量数据计算<strong>回归到真实值</strong>，这就是回归的由来。通过<strong>有监督的学习</strong>，学习到由x到y的映射h，利用该映射关系对未知的数据进行预估，因为y为连续值，所以是<strong>回归问题。</strong></li><li>逻辑回归使用回归函数，来解决<strong>分类问题</strong>，线性回归的结果Y带入一个非线性变换的Sigmoid函数中，得到[0,1]之间取值范围的数S，<strong>S可以把它看成是一个概率值</strong>，如果我们设置概率阈值为0.5，那么S大于0.5可以看成是正样本，小于0.5看成是负样本，就可以进行分类了。</li><li><strong>线性回归的损失函数</strong>。一般使用最小二乘法，则MSE误差平方为$(yi−hθ(xi))^2$找到合适的参数</li></ol></li><li>逻辑回归<ol><li>逻辑回归=线性回归+sigmoid函数</li><li>公式: $z=wx+b, y=\frac{1}{1+e^{-z}}$。判别式是$f(x)=sign(y)$</li><li>损失函数（交叉熵损失函数）:$L = - \sum_i^n (ylogp+(1-y)log(1-p))$。 前面的y是标签，后面的p是预测出来的分布。<ol><li>损失函数求导。损失函数使用最大似然估计:$L=- \sum _ { n = 1 } ^ { N } ( y _ { n } \ln ( p ) + ( 1 - y _ { n } ) \ln ( 1 - p ) )$,这里的$p=\frac{1}{1+e^{-z}}$就是这个值的概率。</li><li>$\frac{\partial f(x)}{\partial z}=\frac{1}{1+e^{-z}}*\frac{e^{-z}}{1+e^{-z}}=p(1-p)$</li><li>最终求导结果为$\frac{\partial L}{\partial w}= -\frac{1}{n}\sum_{n=1}^{N}(y_i-\frac{1}{1+e^{-z}})x$</li></ol></li></ol></li><li>案例：<ol><li>p(Y=1|x)=p(x)</li><li>p(y=0|x)=1-p(x).p就是函数</li></ol></li><li>极大似然估计</li></ol><p>推导W、b的梯度下降步骤。</p><h2 id=当label-1-1下的公式推导>当label={-1, +1}下的公式推导</h2><p><a href=https://github.com/datawhalechina/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/machine-learning>https://github.com/datawhalechina/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/machine-learning</a></p><ol><li>在label={-1,+1},则$\left. \begin{array} { l } { p ( y = 1 | x ) = h _ { w } ( x ) } \ { p ( y = - 1 | x ) = 1 - h _ { w } ( x ) } \end{array} \right.$</li><li>由于sigmoid函数的特性：<ol><li>$\left. \begin{array} { l } { h ( - x ) = 1 - h ( x ) } \ 综上{ p ( y | x ) = h _ { w } ( y x ) } \end{array} \right.$</li></ol></li><li>仍然使用极大似然函数，$L=\prod p(y|x;w)=\prod h(yx)=\prod_{ i = 1 } ^ { m } \frac{ 1 }{ 1 + e ^ { - y _ { i } w x _ { i } }}$</li><li>再求导计算即可。</li></ol><h1 id=面试相关>面试相关</h1><ol><li><p>如何多分类：</p><ol><li>一对一：N个类别两两配对</li><li>一对多：每次将一个例作为正例。其他作为反例。</li><li>多对多。多个类正类，多个类反类。需要进一步的设置。</li></ol></li><li><p>逻辑回归优缺点：</p><ol><li>优点<ol><li>LR的可解释性强、特征的权重可以看到不同特征的影响。模型效果不错，运行速度快（仅和特征数目有关）。方便调整阈值来做分类。</li></ol></li><li>缺点：<ol><li>特征工程复杂。需要较多的特征工程和归一化。</li><li>准确率不足（简单的线性回归，和SVM相比）</li><li>难以处理不平衡的数据。（没有不平衡数据的处理方案）</li></ol></li><li>使用场景：大规模数据线性分类。</li><li>记忆：LR简单，解释性强，适用于大规模数据的线性分类。但由于简单所以准确率不足，对特征工程要求较高。</li></ol></li><li><p>逻辑回归训练技巧</p><ol><li>特征离散化</li></ol></li><li><p><strong>逻辑斯特回归为什么要对特征进行离散化</strong> （ 对特征离散化，让特征里没有连续值）</p><ol><li>逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，<strong>每个变量有单独的权重，相当于为模型引入了非线性</strong>，能够提升模型表达能力，加大拟合</li><li>稀疏向量内积乘法运算速度快计算结果方便存储，容易扩展</li><li><strong>离散化后的特征对异常数据有很强的鲁棒性</strong>：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰。</li></ol></li><li><p><strong>线性回归</strong>与逻辑回归的区别</p><ol><li>线性回归主要解决回归任务，逻辑回归主要解决分类问题。</li><li>线性回归的输出一半是连续的，逻辑回归的输出一般是离散的。</li><li>线性回归的损失函数是MSE,逻辑回归中，采用的是负对数损失函数</li></ol></li><li><p><strong>为什么逻辑回归比线性回归要好</strong>？</p><ol><li>在特征到结果的映射中加入了一层sigmoid函数（非线性）映射，即先把特征线性求和，</li><li>另外线性回归在整个实数域范围内进行预测，敏感度一致，而分类范围，需要在0,1间的一种回归模型，因而对于这类问题来说，逻辑回归的鲁棒性比线性回归的要好。</li><li>逻辑回归的损失函数让它只有靠近决策取阈的样本影响大，所以鲁棒性更好。</li><li>总结：1. 加入非线性，2靠近决策区域影响更大，效果更好。3. 它在0-1进行预测，比线性回归解空间小。</li></ol></li><li><p><strong>LR为什么使用sigmoid函数？,为什么不使用MSE</strong></p><ol><li>而Sigmoid能够把它映射到[0,1]之间。正好这个是概率的范围。</li><li>Sigmoid是连续光滑的。</li><li>Sigmoid也让逻辑回归的损失函数成为凸函数，这也是很好的性质。可以寻找到一个全局最优点进行下降。</li><li>使用MSE，则不是一个凸函数。根据损失函数可以得到。</li></ol></li><li><p><strong>逻辑回归为什么不使用最小二乘法，而使用最大似然估计</strong>。注意区分，这是损失函数，上一个问题是激活函数的问题。</p><ol><li>在最小二乘法下，逻辑回归损失函数非凸。</li><li>非凸判定：二阶导存在且为正。则为凸函数。意思是在凸集中局部最优等于全局最优。</li></ol></li><li><p><strong>LR和SVM有什么不同吗</strong></p><ol><li>相同<ol><li>两个方法都可以增加不同的正则化项</li><li>LR和SVM都可以<strong>处理分类问题，且一般都用于处理线性二分类问题</strong></li></ol></li><li>不同：<ol><li>LR是参数模型，SVM是非参数模型。<strong>参数模型即需要知道数据的分布参数。</strong></li><li><strong>从目标函数来看</strong>，区别在于逻辑回归采用的是交叉熵损失函数，SVM采用的是hinge loss，这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。</li><li>SVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。</li><li>LR在特别是大规模线性分类时比较方便。**SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,**这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。</li><li>LR依赖数据分布。LR和所有的数据相关。SVM不依赖。</li><li>LR能做的 SVM能做，但可能在准确率上有问题，SVM能做的LR有的做不了。</li></ol></li><li></li><li>总结。模型类型，从损失函数，支持向量上面进行分析。</li></ol></li><li><p>sigmoid作为激活函数的缺点（难算，非中心化，梯度消失）</p></li></ol></div><footer class=post-footer><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>逻辑回归lr</p><p style=word-break:break-all><span>链接：</span>
https://yanyulinxi.github.io/post/study/deeplearning/lr%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</p><p><span>作者：</span>阳阳</p><p><span>邮箱：</span>yanyulinxi@qq.com</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick="var qr=document.getElementById('QR');qr.style.display==='none'?qr.style.display='block':qr.style.display='none'">
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/knnk%E6%9C%80%E8%BF%91%E9%82%BB%E5%B1%85/ rel=next title=KnnK最近邻居><i class="fa fa-chevron-left"></i>KnnK最近邻居</a></div><div class="post-nav-prev post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0baimian/ rel=prev title=百面机器学习baimian>百面机器学习baimian
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/linxi_icon.png alt=阳阳><p class=site-author-name itemprop=name>阳阳</p><p class="site-description motion-element" itemprop=description>再平凡的人也有属于他自己的梦想!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>129</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>34</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/yanyuLinxi target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>GitHub</a></span>
<span class=links-of-author-item><a href=https://space.bilibili.com/19237450 target=_blank title=哔哩哔哩><i class="fa fa-fw fa-globe"></i>哔哩哔哩</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0>论文阅读笔记</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90>异常行为分析</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python%E7%9B%B8%E5%85%B3%E5%BA%93%E5%AD%A6%E4%B9%A0>Python相关库学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7>深度学习辅助工具</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%BA%93>机器学习相关库</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/java%E5%AD%A6%E4%B9%A0>Java学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/insider-threat>Insider threat</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/leetcode%E5%AD%A6%E4%B9%A0>Leetcode学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E7%BE%8E%E9%A3%9F%E7%82%B9%E8%AF%84>美食点评</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/rnn>Rnn</a></li></ul></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span><span class=copyright-author>阳阳的人间旅游日记</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.81.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv><i class="fa fa-user"></i><span class=busuanzi-value id=busuanzi_value_site_uv></span></span><span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i><span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href style=font-weight:700 target=_blank></a></span><span class=separator-line>/</span>
<span class=license-num><a href target=_blank></a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i><span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript src=/js/search.js></script><script type=text/javascript src=/js/affix.js></script><script type=text/javascript src=/js/scrollspy.js></script><script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script><script type=text/javascript>$(function(){$('.post-body').viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script><script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script></body></html>