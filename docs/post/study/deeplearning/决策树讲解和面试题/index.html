<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>决策树讲解和面试题 - 希望至美，永不凋零</title><meta name=keywords content="博客,程序员,思考,读书,笔记,技术,分享"><meta name=author content="烟雨临溪"><meta property="og:title" content="决策树讲解和面试题"><meta property="og:site_name" content="希望至美，永不凋零"><meta property="og:image" content="/img/author.jpg"><meta name=title content="决策树讲解和面试题 - 希望至美，永不凋零"><meta name=description content="欢迎来到临溪的博客站，个人主要专注于机器学习、深度学习的相关研究。在这里分享自己的学习心得。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i><a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span><span class=site-title>希望至美，永不凋零</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>让我们消除隔阂的，不是无所不知的脑袋，而是手拉手，坚决不放弃的那颗心</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span><span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=http://next.lisenhui.cn/post/study/deeplearning/%E5%86%B3%E7%AD%96%E6%A0%91%E8%AE%B2%E8%A7%A3%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/ itemprop=url>决策树讲解和面试题</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i><span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="20200-02-20">20200-02-20</time></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i><span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>3257 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i><span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>7分钟</span></span>
<span id=/post/study/deeplearning/%E5%86%B3%E7%AD%96%E6%A0%91%E8%AE%B2%E8%A7%A3%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/ class=leancloud_visitors data-flag-title=决策树讲解和面试题>|
<i class="fa fa-binoculars fa-fw"></i><span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><h1 id=决策树>决策树</h1><ol><li>决策树算法采用树形结构，使用层层推理来实现最终的分类。决策树由下面几种元素构成：<ol><li><strong>根节点</strong>：包含样本的全集</li><li><strong>内部节点</strong>：对应特征属性测试</li><li><strong>叶节点</strong>：代表决策的结果</li></ol></li><li>预测时，在树的内部节点处用<strong>某一属性值</strong>进行判断，根据判断结果决定进入<strong>哪个分支节点</strong>，<strong>直到到达叶节点处</strong>，得到<strong>分类结果</strong>。</li></ol><h1 id=增益计算>增益计算</h1><ol><li>ID3：信息增益<ol><li>某一个属性的信息熵 $Ent(D) = -\sum_{k=1}^y p_k log p_k$。其中在所有标签y中，第k类标签所占的比例为$p_k$。分类越纯，$p_k$就越大，信息熵就越小。即信息熵越小，则信息量越小，混乱程度越低，置信度越高。</li><li>属性a信息增益为:$Gain(D, a)=Ent(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|}Ent(D^v)$ 其中属性（特征）a的分类有v种，第v类的分类数量为$D^v$。</li><li>信息增益的缺点：偏爱属性分类多的特征。属性分类多的特征，每一分类中的越纯的可能性越大。信息熵就低，信息增益就高。所以偏爱特征分类多的特征。比如按照id来分类，则信息增益最大。</li></ol></li><li>C4.5：信息增益率<ol><li>为了解决上述缺点。将信息熵除以一个固有值。</li><li>$Gain_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}$，其中$IV(a)=-\sum_{v=1}^V \frac{|D^v|}{|D|} log \frac{|D^v|}{|D|}$ 固有值为属性a的每一种类所占的样本的比例的熵。</li><li>信息增益率偏爱特征分类数量少的特征。所以C4.5的信息选择为，先选择信息增益大于平均值的属性。然后在其中选择信息增益率最大的属性。</li></ol></li><li>CART：基尼系数<ol><li>由于熵运算非常耗时。所以采用计算更快的基尼系数:$Gain(D)=\sum_{y=1}^Y\sum_{k'\neq k}p_kp_k'=1-\sum_{k=1}^yp_k^2$ 其中$p_k$为标签y中第k类所占的比例。Gini系数表示了随机抽两个样本，它们标签不一致的概率。Gini越小，纯度越高。基尼系数替代信息熵，则是CART计算信息增益的方法。注意：算信息增益时，基尼系数仍然需要乘以$\frac{|D^v|}{|D|}$</li><li>基尼系数约等于熵模型的一阶泰勒展开。</li><li>当CART为回归树时，采用MSE平方差代替基尼系数作为增益计算。</li></ol></li></ol><h1 id=连续值的处理>连续值的处理</h1><ol><li>C4.5和cart拥有相同的连续值处理<ol><li>对于连续值，排序后，选取每两个值的平均值作为候选值。根据增益计算选取最佳增益的候选值进行分裂。详细点说：将连续特征离散化，假设 n 个样本的连续特征 A 有 m 个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点；</li><li>如果当前属性为连续属性，则该属性在后面还可以参与子节点的产生选择过程。</li></ol></li></ol><h1 id=缺失值的处理>缺失值的处理</h1><ol><li>C4.5采用将缺失样本同时划分入所有子节点，为每个确实样本赋予不同权重。形式上等价于使用不同概率将缺失样本划入子节点。<ol><li>属性的选择：首先仅使用非缺失样本进行属性选择。每个属性的计算$Gain(D, a) = \rho * Gain(D, a)$，其中$\rho=\frac{\sum_{x\in \hat{D}}w_x}{\sum_{x\in D} w_x}$，即非缺失值样本所占的比例。</li><li>缺失值样本的划分：将缺失值同时划分入左右子节点，样本权值调整为:$w_x=\hat{r_v}*w_x$， 其中$\hat{r_v}$为非缺失值样本中，该分类中，样本所占的比例。即17个样本，2个缺失。15个样本分为5,8,2.则每一类的$\hat{r_v}$比例为$\frac{5}{15},\frac{8}{15},\frac{2}{15}$</li></ol></li><li>CART采用代理测试来估计缺失值<ol><li>属性的选择：使用没有缺失值的样本进行划分，并进行惩罚。和C4.5类似。缺失为20%则惩罚20%的权重</li><li>缺失值样本的划分：为每个属性建立一个代理属性（不管是否缺失都会这么做）。代理属性满足和主分裂类似，且有着正关联。使用代理属性对缺失值进行划分。</li></ol></li></ol><h1 id=剪枝>剪枝</h1><ol><li>C4.5剪枝<ol><li>预剪枝：在分裂时进行剪枝<ol><li>限制树的节点个数：节点数据比例低于某一阈值</li><li>限制树的高度：节点特征都已经分裂。或者树到达一定高度。</li><li>利用分类指标：节点划分前准确率比划分后准确率高。</li><li>总结：常见树防止过拟合的方法。树高度、节点个数，指标。</li><li>预剪枝优点：节省大量的训练开销，降低过拟合。预剪枝缺点：存在欠拟合风险（存在当前性能下降，后续性能大幅提高的情形）</li></ol></li><li>后剪枝：<ol><li>使用测试集进行验证：对所有非叶子节点，自底向上的进行剪枝：如果这个节点不分裂，效果保持或者不下降，则可以替换这个子树。</li><li>优点：后剪枝欠拟合风险小很多，泛化性能会优于预剪枝。缺点：时间开销大。</li></ol></li><li>悲观后剪枝TODO:</li></ol></li><li>CART剪枝：<ol><li>基于代价复杂度剪枝：<ol><li>这种方法会生成一系列树，每个树都是通过将前面的树的某个或某些子树替换成一个叶节点而得到的，这种方法需要使用一个单独的测试数据集来评估所有的树，根据它们在测试数据集熵的分类性能选出最佳的树。</li><li>在所有的子树中，找出那些使用了较多节点，却使错误率下降最低的子树，把这些子树剪裁掉。</li></ol></li><li>指标$R(T)=e(T)*p(T)$，e(T)指该节点的错分率。如二分类，1占13，0占7，则错分率为7/20（因为这个节点被判为1）。p(T)是该节点样本数占样本总数的比例。计算当前节点的R(T)，计算当前节点下的所有叶子节点的R(T)，得到代价复杂度$\alpha=\frac{R(T)-R(T_t)}{N-1}$N为该节点下叶子节点数量。对于这个值，分子越大说明分类效果越好。分母越小说明复杂度越低。整个值越大越好。</li><li>代价复杂度剪枝：<ol><li>循环对代价复杂度参数最小的节点进行剪枝（有多个节点同时取到最小值时取叶子节点最多的节点），直到只剩下根节点，可得到一系列的剪枝数{T0, T1, T2, …, Tm}，其中T0为原始的决策树，Tm为根节点，Ti+1为Ti剪枝后的结果。</li><li>当树只有根节点时结束。记录下所有的树，根据实际误差获得最优决策树。</li></ol></li></ol></li></ol><h1 id=三个树的比较>三个树的比较：</h1><ol><li><strong>划分标准的差异</strong>：ID3 使用信息增益偏向特征值多的特征，C4.5 使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART 使用基尼指数克服 C4.5 需要求 log 的巨大计算量，偏向于特征值较多的特征。</li><li><strong>使用场景的差异</strong>：ID3 和 C4.5 都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5 是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li><li><strong>样本数据的差异</strong>：ID3 只能处理离散数据且缺失值敏感，C4.5 和 CART 可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议 C4.5、大样本建议 CART。C4.5 处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART 本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li><li><strong>样本特征的差异</strong>：ID3 和 C4.5 层级之间只使用一次特征，CART 可多次重复使用特征；</li><li><strong>剪枝策略的差异</strong>：ID3 没有剪枝策略，C4.5 是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</li></ol><h1 id=决策树的优缺点>决策树的优缺点</h1><ol><li>优点：<ol><li>决策树易于理解和解释，可以可视化分析，<strong>容易提取出规则</strong>；</li><li>比较适合处理<strong>有缺失属性的样本；</strong></li><li>测试数据集时，<strong>运行速度比较快；</strong></li></ol></li><li>缺点：<ol><li>容易发生<strong>过拟合</strong>（随机森林可以很大程度上减少过拟合）；</li><li>容易忽略数据集中属性的<strong>相互关联</strong>；</li><li>对于那些各类别样本数量不一致的数据，在决策树中，进行属性划分时，<strong>不同的判定准则会带来不同的属性选择倾向</strong>；</li></ol></li></ol><h1 id=随机森林>随机森林</h1><p>随机森林属于bagging</p><p>步骤：</p><ol><li>样本选择：一个样本容量为N的样本，有放回的抽取N次，每次抽取1个，最终形成了N个样本。这选择好了的N个样本用来训练一个决策树，作为决策树根节点处的样本。</li><li>属性选择：当每个样本有M个属性时，在决策树的每个节点需要分裂时，随机从这M个属性中选取出m个属性，满足条件m &#171; M。然后从这m个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。</li><li>决策树形成过程中每个节点都要按照步骤2来分裂（很容易理解，如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。一直到不能够再分裂为止。注意整个决策树形成过程中没有进行剪枝。</li><li>按照步骤1~3建立大量的决策树，这样就构成了随机森林了。</li></ol><h1 id=面试题>面试题</h1><ol><li>部分面试题：<ol><li><a href=https://github.com/datawhalechina/daily-interview/tree/master/AI%E7%AE%97%E6%B3%95/machine-learning>https://github.com/datawhalechina/daily-interview/tree/master/AI%E7%AE%97%E6%B3%95/machine-learning</a></li></ol></li><li>给出案例手算信息增益（ID3,C4.5,CART)(面试中遇到过)</li></ol><h1 id=参考资料>参考资料</h1><ol><li>《机器学习》周志华。（推荐）</li><li><a href=https://zhuanlan.zhihu.com/p/133838427>https://zhuanlan.zhihu.com/p/133838427</a></li><li><a href=https://zhuanlan.zhihu.com/p/85731206>https://zhuanlan.zhihu.com/p/85731206</a></li></ol></div><footer class=post-footer><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>决策树讲解和面试题</p><p><span>链接：</span>http://next.lisenhui.cn/post/study/deeplearning/%E5%86%B3%E7%AD%96%E6%A0%91%E8%AE%B2%E8%A7%A3%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/</p><p><span>作者：</span>烟雨临溪</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick="var qr=document.getElementById('QR');qr.style.display==='none'?qr.style.display='block':qr.style.display='none'">
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=http://next.lisenhui.cn/post/study/deeplearning/metrics%E6%8C%87%E6%A0%87%E8%AE%B2%E8%A7%A3%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/ rel=next title=指标讲解和面试题><i class="fa fa-chevron-left"></i>指标讲解和面试题</a></div><div class="post-nav-prev post-nav-item"><a href=http://next.lisenhui.cn/post/study/deeplearning/xgboost%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC%E5%92%8C%E9%9D%A2%E8%AF%95%E9%A2%98/ rel=prev title=XGBoost理论推导和面试题>XGBoost理论推导和面试题
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/linxi_icon.png alt=烟雨临溪><p class=site-author-name itemprop=name>烟雨临溪</p><p class="site-description motion-element" itemprop=description>再平凡的人也有属于他自己的梦想!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>112</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>31</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/yanyuLinxi target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>GitHub</a></span>
<span class=links-of-author-item><a href=https://space.bilibili.com/19237450 target=_blank title=哔哩哔哩><i class="fa fa-fw fa-globe"></i>哔哩哔哩</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0>论文阅读笔记</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90>异常行为分析</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python%E7%9B%B8%E5%85%B3%E5%BA%93%E5%AD%A6%E4%B9%A0>Python相关库学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%BA%93>机器学习相关库</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/java%E5%AD%A6%E4%B9%A0>Java学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/insider-threat>Insider threat</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/leetcode%E5%AD%A6%E4%B9%A0>Leetcode学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E7%BE%8E%E9%A3%9F%E7%82%B9%E8%AF%84>美食点评</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/rnn>Rnn</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>科研学习笔记</a></li></ul></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span><span class=copyright-author>希望至美，永不凋零</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.81.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv><i class="fa fa-user"></i><span class=busuanzi-value id=busuanzi_value_site_uv></span></span><span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i><span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href=https://www.ucloud.cn/ style=font-weight:700 target=_blank>UCloud云存储</a></span>
<span class=separator-line>/</span>
<span class=license-num><a href=http://beian.miit.gov.cn target=_blank>未归档</a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i><span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript src=/js/search.js></script><script type=text/javascript src=/js/affix.js></script><script type=text/javascript src=/js/scrollspy.js></script><script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script><script type=text/javascript>$(function(){$('.post-body').viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script><script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script></body></html>