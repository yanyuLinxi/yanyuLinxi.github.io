<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>销量预测比赛-2 - 阳阳的人间旅游日记</title><meta name=keywords content="博客,程序员,思考,读书,笔记,技术,分享"><meta name=author content="阳阳"><meta property="og:title" content="销量预测比赛-2"><meta property="og:site_name" content="阳阳的人间旅游日记"><meta property="og:image" content="/img/author.jpg"><meta name=title content="销量预测比赛-2 - 阳阳的人间旅游日记"><meta name=description content="欢迎来到临溪的博客站，个人主要专注于机器学习、深度学习的相关研究。在这里分享自己的学习心得。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i><a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span><span class=site-title>阳阳的人间旅游日记</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>让我们消除隔阂的，不是无所不知的脑袋，而是手拉手，坚决不放弃的那颗心</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span><span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://yanyulinxi.github.io/post/study/kaggle/writeup/customer_forecast/ itemprop=url>销量预测比赛-2</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i><span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2022-06-21">2022-06-21</time></span>
<span class=post-category>&nbsp; | &nbsp;
<i class="fa fa-folder-o fa-fw"></i><span class=post-meta-item-text>分类：</span>
<span itemprop=about itemscope itemtype=https://schema.org/Thing><a href=/categories/%E5%AD%A6%E4%B9%A0 itemprop=url rel=index style=text-decoration:underline><span itemprop=name>学习</span></a>
&nbsp;</span></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i><span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>3918 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i><span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>8分钟</span></span>
<span id=/post/study/kaggle/writeup/customer_forecast/ class=leancloud_visitors data-flag-title=销量预测比赛-2>|
<i class="fa fa-binoculars fa-fw"></i><span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><p>在第一次的基础上，我们进一步对方案进行改进。</p><p>第一次失败的总结：分桶没有分好，降低了模型效果。缺失值填充也不好使得效果一般。</p><p>将分为以下几个步骤：</p><ol><li>特征工程<ol><li>使用箱线图将特征的异常值(行)进行删除（没有必要，test仍然存在这些值。将分桶作为新特征。不要删除原有特征）</li><li>将倾斜特征删除<ol><li>是否翻新机</li></ol></li><li>将异常值替换为nan</li><li>特征分桶：<ol><li>家庭中唯一订阅者的数量,家庭活跃用户数</li></ol></li><li>构造新特征：（结合地理信息、每分钟单价、超额分钟单价、）</li><li>以上特征送入树模型，以下操作针对其他模型</li><li>存在异常值的特征进行填充。（众数补全、KNN插值补全）</li><li>类别特征one-hot</li><li>连续特征转换分布、归一化</li></ol></li><li>模型调参（时间有限，就选这四个）<ol><li>选择树模型：随机森林、lgbm</li><li>选择其他模型：逻辑回归、MLP</li><li>贝叶斯调参</li></ol></li><li>模型融合<ol><li>stacking</li></ol></li></ol><h2 id=导入数据>导入数据</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>warnings</span>
warnings<span style=color:#666>.</span>filterwarnings(<span style=color:#b44>&#39;ignore&#39;</span>)
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>pandas</span> <span style=color:#a2f;font-weight:700>as</span> <span style=color:#00f;font-weight:700>pd</span>
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>numpy</span> <span style=color:#a2f;font-weight:700>as</span> <span style=color:#00f;font-weight:700>np</span>
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>seaborn</span> <span style=color:#a2f;font-weight:700>as</span> <span style=color:#00f;font-weight:700>sns</span>
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>sweetviz</span> <span style=color:#a2f;font-weight:700>as</span> <span style=color:#00f;font-weight:700>sv</span>
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn</span> <span style=color:#a2f;font-weight:700>import</span> metrics
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>os</span>
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>gc</span>
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>lightgbm</span> <span style=color:#a2f;font-weight:700>as</span> <span style=color:#00f;font-weight:700>lgb</span>
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>xgboost</span> <span style=color:#a2f;font-weight:700>as</span> <span style=color:#00f;font-weight:700>xgb</span>
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>catboost</span> <span style=color:#a2f;font-weight:700>import</span> CatBoostRegressor
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.linear_model</span> <span style=color:#a2f;font-weight:700>import</span> SGDRegressor, LinearRegression, Ridge
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.preprocessing</span> <span style=color:#a2f;font-weight:700>import</span> MinMaxScaler
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>gensim.models</span> <span style=color:#a2f;font-weight:700>import</span> Word2Vec
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>math</span>
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>tqdm</span> <span style=color:#a2f;font-weight:700>import</span> tqdm
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.model_selection</span> <span style=color:#a2f;font-weight:700>import</span> StratifiedKFold, KFold
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.metrics</span> <span style=color:#a2f;font-weight:700>import</span> accuracy_score, f1_score, roc_auc_score, log_loss
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>matplotlib.pyplot</span> <span style=color:#a2f;font-weight:700>as</span> <span style=color:#00f;font-weight:700>plt</span>
<span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>time</span>

pd<span style=color:#666>.</span>set_option(<span style=color:#b44>&#39;display.max_rows&#39;</span>, <span style=color:#666>500</span>)
</code></pre></div><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>train_data <span style=color:#666>=</span> pd<span style=color:#666>.</span>read_csv(<span style=color:#b44>&#34;data/train.csv&#34;</span>)
test_data <span style=color:#666>=</span> pd<span style=color:#666>.</span>read_csv(<span style=color:#b44>&#34;data/test.csv&#34;</span>)
train_data[<span style=color:#b44>&#34;train&#34;</span>] <span style=color:#666>=</span> <span style=color:#666>1</span>
test_data[<span style=color:#b44>&#34;train&#34;</span>]<span style=color:#666>=</span> <span style=color:#666>0</span>
data_all <span style=color:#666>=</span> pd<span style=color:#666>.</span>concat([train_data, test_data], axis<span style=color:#666>=</span><span style=color:#666>0</span>)
data_all <span style=color:#666>=</span> data_all<span style=color:#666>.</span>reset_index(drop<span style=color:#666>=</span>True)
</code></pre></div><h2 id=特征工程>特征工程</h2><h3 id=异常特征处理>异常特征处理</h3><p>将"是否翻新机" 丢弃</p><p>将"家庭中唯一订阅者的数量,家庭活跃用户数"特征分桶</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>data_all<span style=color:#666>.</span>loc[data_all[<span style=color:#b44>&#34;家庭中唯一订阅者的数量&#34;</span>]<span style=color:#666>&gt;</span><span style=color:#666>12</span>, <span style=color:#b44>&#34;家庭中唯一订阅者的数量&#34;</span>]<span style=color:#666>=</span><span style=color:#666>12</span>
data_all<span style=color:#666>.</span>loc[data_all[<span style=color:#b44>&#34;家庭活跃用户数&#34;</span>]<span style=color:#666>&gt;</span><span style=color:#666>9</span>, <span style=color:#b44>&#34;家庭活跃用户数&#34;</span>]<span style=color:#666>=</span><span style=color:#666>9</span>
data_all <span style=color:#666>=</span> data_all<span style=color:#666>.</span>drop(columns<span style=color:#666>=</span>[<span style=color:#b44>&#34;是否翻新机&#34;</span>])
</code></pre></div><h3 id=处理缺失值>处理缺失值</h3><p>先将几个不方便使用众数填充的，使用KNN进行填充</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.impute</span> <span style=color:#a2f;font-weight:700>import</span> KNNImputer
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.preprocessing</span> <span style=color:#a2f;font-weight:700>import</span> StandardScaler

<span style=color:#a2f;font-weight:700>def</span> <span style=color:#00a000>fill_na</span>(x):
    x[x<span style=color:#666>&lt;</span><span style=color:#666>0</span>] <span style=color:#666>=</span> np<span style=color:#666>.</span>nan
    <span style=color:#a2f;font-weight:700>return</span> x

choose_col <span style=color:#666>=</span> <span style=color:#b44>&#34;地理区域,手机网络功能,婚姻状况,家庭成人人数,预计收入&#34;</span><span style=color:#666>.</span>split(<span style=color:#b44>&#34;,&#34;</span>)
data_all[choose_col] <span style=color:#666>=</span> data_all[choose_col]<span style=color:#666>.</span>apply(func<span style=color:#666>=</span>fill_na)
knn_col <span style=color:#666>=</span> [col <span style=color:#a2f;font-weight:700>for</span> col <span style=color:#a2f;font-weight:700>in</span> data_all<span style=color:#666>.</span>columns <span style=color:#a2f;font-weight:700>if</span> col <span style=color:#a2f;font-weight:700>not</span> <span style=color:#a2f;font-weight:700>in</span> [<span style=color:#b44>&#34;客户ID&#34;</span>, <span style=color:#b44>&#34;是否流失&#34;</span>, <span style=color:#b44>&#34;type&#34;</span>]]
imputer <span style=color:#666>=</span> KNNImputer(n_neighbors<span style=color:#666>=</span><span style=color:#666>5</span>)
data_all[knn_col] <span style=color:#666>=</span> pd<span style=color:#666>.</span>DataFrame(imputer<span style=color:#666>.</span>fit_transform(data_all[knn_col]),columns <span style=color:#666>=</span> knn_col)


</code></pre></div><p>对数据中出现的负值为-1的列，添加个数到新特征。对于出现负值的连续特征（可能小于-1），添加小于0的特征个数到到新特征。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#a2f;font-weight:700>def</span> <span style=color:#00a000>getres1</span>(row):
    <span style=color:#a2f;font-weight:700>return</span> <span style=color:#a2f>len</span>([x <span style=color:#a2f;font-weight:700>for</span> x <span style=color:#a2f;font-weight:700>in</span> row<span style=color:#666>.</span>values <span style=color:#a2f;font-weight:700>if</span> <span style=color:#a2f>type</span>(x)<span style=color:#666>==</span><span style=color:#a2f>int</span> <span style=color:#a2f;font-weight:700>and</span> x<span style=color:#666>==-</span><span style=color:#666>1</span>])

<span style=color:#a2f;font-weight:700>def</span> <span style=color:#00a000>getresneg</span>(row):
    <span style=color:#a2f;font-weight:700>return</span> <span style=color:#a2f>len</span>([x <span style=color:#a2f;font-weight:700>for</span> x <span style=color:#a2f;font-weight:700>in</span> row<span style=color:#666>.</span>values <span style=color:#a2f;font-weight:700>if</span> <span style=color:#a2f>type</span>(x) <span style=color:#a2f;font-weight:700>in</span> [<span style=color:#a2f>int</span>, <span style=color:#a2f>float</span>] <span style=color:#a2f;font-weight:700>and</span> x<span style=color:#666>&lt;</span><span style=color:#666>0</span>])

data_all[<span style=color:#b44>&#39;neg1&#39;</span>] <span style=color:#666>=</span> data_all[data_all<span style=color:#666>.</span>columns]<span style=color:#666>.</span>apply(<span style=color:#a2f;font-weight:700>lambda</span> row:getres1(row),axis<span style=color:#666>=</span><span style=color:#666>1</span>)
data_all<span style=color:#666>.</span>loc[data_all[<span style=color:#b44>&#39;neg1&#39;</span>]<span style=color:#666>&gt;</span><span style=color:#666>10</span>,<span style=color:#b44>&#39;neg1&#39;</span>] <span style=color:#666>=</span> <span style=color:#666>10</span>  <span style=color:#080;font-style:italic>#平滑处理</span>
data_all[<span style=color:#b44>&#39;neg_all&#39;</span>] <span style=color:#666>=</span> data_all[data_all<span style=color:#666>.</span>columns]<span style=color:#666>.</span>apply(<span style=color:#a2f;font-weight:700>lambda</span> row:getresneg(row),axis<span style=color:#666>=</span><span style=color:#666>1</span>)
</code></pre></div><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#080;font-style:italic># 对所有数据，为负值的，替换为nan</span>
data_all <span style=color:#666>=</span> data_all<span style=color:#666>.</span>apply(func<span style=color:#666>=</span>fill_na)
</code></pre></div><h3 id=构造新特征>构造新特征</h3><p>每分钟单价,超额分钟单价</p><p>结合地理区域: 分钟单价,超额分钟单价,当前手机价格,家庭活跃用户数量,平均月费用,超额费用,使用高峰语音通话的平均不完整分钟数,新手机用户,信用等级代码,平均掉线语音呼叫树,平均丢弃数据呼叫数,平均占线语音呼叫数</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#080;font-style:italic>#data_all[&#34;每分钟单价&#34;] = data_all[&#34;每月平均使用分钟数&#34;]/data_all[&#34;平均语音费用&#34;]</span>
data_all[<span style=color:#b44>&#34;超额分钟单价&#34;</span>] <span style=color:#666>=</span> data_all[<span style=color:#b44>&#34;平均超额使用分钟数&#34;</span>]<span style=color:#666>/</span>data_all[<span style=color:#b44>&#34;平均超额费用&#34;</span>]
</code></pre></div><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>data_all[<span style=color:#b44>&#34;超额分钟单价&#34;</span>]<span style=color:#666>.</span>isna()<span style=color:#666>.</span>sum()
</code></pre></div><pre><code>72772
</code></pre><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>choose_cols <span style=color:#666>=</span> <span style=color:#b44>&#34;地理区域,每月平均使用分钟数,平均语音费用,平均超额使用分钟数,平均超额费用,当前手机价格,平均月费用,使用高峰语音通话的平均不完整分钟数,新手机用户,信用等级代码,平均掉线语音呼叫数,平均丢弃数据呼叫数,平均占线语音呼叫数&#34;</span><span style=color:#666>.</span>split(<span style=color:#b44>&#34;,&#34;</span>)
data_all_gb <span style=color:#666>=</span> data_all[choose_cols]<span style=color:#666>.</span>groupby(<span style=color:#b44>&#34;地理区域&#34;</span>)
<span style=color:#a2f;font-weight:700>for</span> col <span style=color:#a2f;font-weight:700>in</span> choose_cols:
    data_all[<span style=color:#b44>&#34;地理平均&#34;</span><span style=color:#666>+</span>col] <span style=color:#666>=</span> data_all_gb[col]<span style=color:#666>.</span>transform(<span style=color:#b44>&#39;mean&#39;</span>)
</code></pre></div><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>data_all[<span style=color:#b44>&#34;地理平均每分钟单价&#34;</span>] <span style=color:#666>=</span> data_all[<span style=color:#b44>&#34;地理平均每月平均使用分钟数&#34;</span>]<span style=color:#666>/</span>data_all[<span style=color:#b44>&#34;地理平均平均语音费用&#34;</span>]
data_all[<span style=color:#b44>&#34;地理平均超额分钟单价&#34;</span>] <span style=color:#666>=</span> data_all[<span style=color:#b44>&#34;地理平均平均超额使用分钟数&#34;</span>]<span style=color:#666>/</span>data_all[<span style=color:#b44>&#34;地理平均平均超额费用&#34;</span>]
</code></pre></div><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>train_gb <span style=color:#666>=</span> train_data<span style=color:#666>.</span>groupby(<span style=color:#b44>&#34;地理区域&#34;</span>)
all_info <span style=color:#666>=</span> {}
<span style=color:#a2f;font-weight:700>for</span> kind, kind_data <span style=color:#a2f;font-weight:700>in</span> train_gb:
    info <span style=color:#666>=</span> {}
    info[<span style=color:#b44>&#39;地理人口数量&#39;</span>] <span style=color:#666>=</span> <span style=color:#a2f>len</span>(kind_data)
    info[<span style=color:#b44>&#39;是否流失_均值&#39;</span>] <span style=color:#666>=</span> kind_data[<span style=color:#b44>&#34;是否流失&#34;</span>]<span style=color:#666>.</span>mean()
    all_info[kind] <span style=color:#666>=</span> info
brand_fe <span style=color:#666>=</span> pd<span style=color:#666>.</span>DataFrame(all_info)<span style=color:#666>.</span>T<span style=color:#666>.</span>reset_index()<span style=color:#666>.</span>rename(columns<span style=color:#666>=</span>{<span style=color:#b44>&#34;index&#34;</span>: <span style=color:#b44>&#34;地理区域&#34;</span>})
data_all <span style=color:#666>=</span> data_all<span style=color:#666>.</span>merge(brand_fe, how<span style=color:#666>=</span><span style=color:#b44>&#39;left&#39;</span>, on<span style=color:#666>=</span><span style=color:#b44>&#39;地理区域&#39;</span>)
</code></pre></div><h3 id=处理特征用于其他模型>处理特征用于其他模型</h3><ul><li><input checked disabled type=checkbox> 众数补全所有nan</li><li><input disabled type=checkbox> 类别特征转为one-hot</li><li><input checked disabled type=checkbox> 连续特征转换分布、并归一化</li></ul><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#080;font-style:italic># data_all_other_model = data_all.copy()</span>
<span style=color:#080;font-style:italic># data_all_other_model = data_all_other_model.apply(func=fill_na)</span>


<span style=color:#080;font-style:italic># 所有的负值填充为众数</span>
data_all <span style=color:#666>=</span> data_all<span style=color:#666>.</span>replace(np<span style=color:#666>.</span>inf, np<span style=color:#666>.</span>nan) <span style=color:#080;font-style:italic>#替换正inf为-1</span>
data_all <span style=color:#666>=</span> data_all<span style=color:#666>.</span>apply(<span style=color:#a2f;font-weight:700>lambda</span> col:col<span style=color:#666>.</span>fillna(col<span style=color:#666>.</span>mode()[<span style=color:#666>0</span>]))

<span style=color:#080;font-style:italic># # 连续特征转换分布、并归一化</span>
<span style=color:#080;font-style:italic># numberic_features = &#34;当前手机价格,当前设备使用天数,平均月费用,每月平均使用分钟数,过去六个月的平均每月使用分钟数,过去六个月的平均每月通话次数,过去六个月的平均月费用&#34;.split(&#34;,&#34;)</span>

<span style=color:#080;font-style:italic># def log_norm_trans(col):</span>
<span style=color:#080;font-style:italic>#     col = np.log(col+1)</span>
<span style=color:#080;font-style:italic>#     col = (col - np.min(col)) / (np.max(col) - np.min(col))</span>
<span style=color:#080;font-style:italic>#     return col</span>

<span style=color:#080;font-style:italic># data_all_other_model[numberic_features] = data_all_other_model[numberic_features].apply(log_norm_trans)</span>
</code></pre></div><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>data_all[<span style=color:#b44>&#34;是否双频&#34;</span>]<span style=color:#666>.</span>value_counts()
</code></pre></div><pre><code>1.0    121088
0.0     58912
Name: 是否双频, dtype: int64
</code></pre><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.model_selection</span> <span style=color:#a2f;font-weight:700>import</span> cross_val_score
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.metrics</span> <span style=color:#a2f;font-weight:700>import</span> mean_absolute_error,  make_scorer, roc_auc_score

<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.linear_model</span> <span style=color:#a2f;font-weight:700>import</span> LinearRegression, LogisticRegression
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.svm</span> <span style=color:#a2f;font-weight:700>import</span> SVC
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.tree</span> <span style=color:#a2f;font-weight:700>import</span> DecisionTreeRegressor
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.ensemble</span> <span style=color:#a2f;font-weight:700>import</span> RandomForestRegressor, RandomForestClassifier
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.ensemble</span> <span style=color:#a2f;font-weight:700>import</span> GradientBoostingRegressor
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>sklearn.neural_network</span> <span style=color:#a2f;font-weight:700>import</span> MLPRegressor, MLPClassifier
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>xgboost.sklearn</span> <span style=color:#a2f;font-weight:700>import</span> XGBClassifier
<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>lightgbm.sklearn</span> <span style=color:#a2f;font-weight:700>import</span> LGBMClassifier

features_cols <span style=color:#666>=</span> [col <span style=color:#a2f;font-weight:700>for</span> col <span style=color:#a2f;font-weight:700>in</span> data_all<span style=color:#666>.</span>columns <span style=color:#a2f;font-weight:700>if</span> col <span style=color:#a2f;font-weight:700>not</span> <span style=color:#a2f;font-weight:700>in</span> [<span style=color:#b44>&#34;客户ID&#34;</span>, <span style=color:#b44>&#34;是否流失&#34;</span>]]
train_x <span style=color:#666>=</span> data_all<span style=color:#666>.</span>loc[data_all[<span style=color:#b44>&#34;train&#34;</span>]<span style=color:#666>==</span><span style=color:#666>1</span>, features_cols]
train_y <span style=color:#666>=</span> data_all<span style=color:#666>.</span>loc[data_all[<span style=color:#b44>&#34;train&#34;</span>]<span style=color:#666>==</span><span style=color:#666>1</span>, <span style=color:#b44>&#34;是否流失&#34;</span>]
test_x <span style=color:#666>=</span> data_all<span style=color:#666>.</span>loc[data_all[<span style=color:#b44>&#34;train&#34;</span>]<span style=color:#666>==</span><span style=color:#666>0</span>, features_cols]

<span style=color:#080;font-style:italic># def rf_cv(model, train_x, train_y, cv, verbose, **kwargs):</span>
<span style=color:#080;font-style:italic>#     val = cross_val_score(model(**kwargs), x=train_x, y=train_y, verbose=verbose, cv=cv, scoring=make_scorer(roc_auc_score)).mean()</span>
<span style=color:#080;font-style:italic>#     return val</span>

lgbm_param <span style=color:#666>=</span> {
<span style=color:#b44>&#39;num_leaves&#39;</span>: <span style=color:#666>16</span>, 
<span style=color:#b44>&#39;min_data_in_leaf&#39;</span>: <span style=color:#666>20</span>, <span style=color:#080;font-style:italic># 一个叶子上数据的最小数量</span>
<span style=color:#b44>&#39;objective&#39;</span>:<span style=color:#b44>&#39;binary&#39;</span>,
<span style=color:#b44>&#39;max_depth&#39;</span>: <span style=color:#666>-</span><span style=color:#666>1</span>,
<span style=color:#b44>&#39;learning_rate&#39;</span>: <span style=color:#666>0.003</span>,
<span style=color:#b44>&#34;boosting&#34;</span>: <span style=color:#b44>&#34;gbdt&#34;</span>, <span style=color:#080;font-style:italic>#用gbdt算法</span>
<span style=color:#b44>&#34;feature_fraction&#34;</span>: <span style=color:#666>0.18</span>, <span style=color:#080;font-style:italic>#例如 0.18时，意味着在每次迭代中随机选择18％的参数来建树。当特征量少的时候，增大这个值。</span>
<span style=color:#b44>&#34;bagging_freq&#34;</span>: <span style=color:#666>1</span>,
<span style=color:#b44>&#34;bagging_fraction&#34;</span>: <span style=color:#666>0.55</span>, <span style=color:#080;font-style:italic>#每次迭代时用的数据比例， 不进行重采样的情况下随机选择部分数据。可以用来加速训练，可以用来处理过拟合。</span>
<span style=color:#b44>&#34;bagging_seed&#34;</span>: <span style=color:#666>14</span>,
<span style=color:#b44>&#34;metric&#34;</span>: <span style=color:#b44>&#39;auc&#39;</span>, <span style=color:#080;font-style:italic># 评价指标=</span>
<span style=color:#b44>&#34;lambda_l1&#34;</span>: <span style=color:#666>0.1</span>,
<span style=color:#b44>&#34;lambda_l2&#34;</span>: <span style=color:#666>0.2</span>, 
<span style=color:#b44>&#34;verbosity&#34;</span>: <span style=color:#666>-</span><span style=color:#666>1</span>}

<span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>mlxtend.classifier</span> <span style=color:#a2f;font-weight:700>import</span> StackingCVClassifier

test <span style=color:#666>=</span> np<span style=color:#666>.</span>zeros(test_x<span style=color:#666>.</span>shape[<span style=color:#666>0</span>])
cv_scores <span style=color:#666>=</span> []
folds <span style=color:#666>=</span> <span style=color:#666>5</span>
seed <span style=color:#666>=</span> <span style=color:#666>42</span>
kf <span style=color:#666>=</span> KFold(n_splits<span style=color:#666>=</span>folds, shuffle<span style=color:#666>=</span>True, random_state<span style=color:#666>=</span>seed)
<span style=color:#a2f;font-weight:700>for</span> i, (train_index, valid_index) <span style=color:#a2f;font-weight:700>in</span> <span style=color:#a2f>enumerate</span>(kf<span style=color:#666>.</span>split(train_x, train_y)):
    <span style=color:#a2f;font-weight:700>print</span>(<span style=color:#b44>&#39;************************************ {} ************************************&#39;</span><span style=color:#666>.</span>format(<span style=color:#a2f>str</span>(i<span style=color:#666>+</span><span style=color:#666>1</span>)))
    trn_x, trn_y, val_x, val_y <span style=color:#666>=</span> train_x<span style=color:#666>.</span>iloc[train_index], train_y[train_index], train_x<span style=color:#666>.</span>iloc[valid_index], train_y[valid_index]


    clf1 <span style=color:#666>=</span> LogisticRegression()
    clf2 <span style=color:#666>=</span> RandomForestClassifier(n_estimators<span style=color:#666>=</span><span style=color:#666>100</span>)
    clf3 <span style=color:#666>=</span> MLPClassifier(solver<span style=color:#666>=</span><span style=color:#b44>&#39;lbfgs&#39;</span>, max_iter<span style=color:#666>=</span><span style=color:#666>100</span>)
    clf4 <span style=color:#666>=</span> LGBMClassifier(<span style=color:#666>**</span>lgbm_param)
    lr <span style=color:#666>=</span> LogisticRegression()

    <span style=color:#080;font-style:italic># Starting from v0.16.0, StackingCVRegressor supports</span>
    sclf <span style=color:#666>=</span> StackingCVClassifier(
        classifiers<span style=color:#666>=</span>[clf1, clf2, clf3, clf4],  <span style=color:#080;font-style:italic># 第一层分类器</span>
        use_probas<span style=color:#666>=</span>True,  <span style=color:#080;font-style:italic># </span>
        meta_classifier<span style=color:#666>=</span>lr,   <span style=color:#080;font-style:italic># 第二层分类器</span>
        random_state<span style=color:#666>=</span><span style=color:#666>42</span>)
    sclf<span style=color:#666>.</span>fit(trn_x, trn_y)
    val_pred <span style=color:#666>=</span> sclf<span style=color:#666>.</span>predict(val_x)
    test_pred <span style=color:#666>=</span> sclf<span style=color:#666>.</span>predict_proba(test_x)[:, <span style=color:#666>1</span>]
    
    <span style=color:#080;font-style:italic>#train[valid_index] = val_pred</span>
    test <span style=color:#666>+=</span> test_pred <span style=color:#666>/</span> kf<span style=color:#666>.</span>n_splits
    cv_scores<span style=color:#666>.</span>append(roc_auc_score(val_y, val_pred))
    
</code></pre></div><pre><code>************************************ 1 ************************************
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
************************************ 2 ************************************
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
************************************ 3 ************************************
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
************************************ 4 ************************************
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
************************************ 5 ************************************
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt
[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1
[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55
[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
</code></pre><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>out <span style=color:#666>=</span> data_all[data_all[<span style=color:#b44>&#34;train&#34;</span>]<span style=color:#666>==</span><span style=color:#666>0</span>]
out[<span style=color:#b44>&#39;是否流失&#39;</span>] <span style=color:#666>=</span> test
out[[<span style=color:#b44>&#39;客户ID&#39;</span>,<span style=color:#b44>&#39;是否流失&#39;</span>]]<span style=color:#666>.</span>to_csv(<span style=color:#b44>&#39;test_sub_5.csv&#39;</span>, index<span style=color:#666>=</span>False)
</code></pre></div><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>
</code></pre></div></div><footer class=post-footer><div class=post-tags><a href=/tags/kaggle rel=tag title=Kaggle>#Kaggle#</a></div><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>销量预测比赛-2</p><p style=word-break:break-all><span>链接：</span>
https://yanyulinxi.github.io/post/study/kaggle/writeup/customer_forecast/</p><p><span>作者：</span>阳阳</p><p><span>邮箱：</span>yanyulinxi@qq.com</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick="var qr=document.getElementById('QR');qr.style.display==='none'?qr.style.display='block':qr.style.display='none'">
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=https://yanyulinxi.github.io/post/study/deeplearning/%E7%BD%AE%E9%A1%B6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E7%BB%8F%E6%80%BB%E7%BB%93/ rel=next title=（置顶）机器学习面经总结（更新中）><i class="fa fa-chevron-left"></i>（置顶）机器学习面经总结（更新中）</a></div><div class="post-nav-prev post-nav-item"><a href=https://yanyulinxi.github.io/post/paperreading/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding/ rel=prev title="Bert Pre Training of Deep Bidirectional Transformers for Language Understanding">Bert Pre Training of Deep Bidirectional Transformers for Language Understanding
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>文章目录</li><li class=sidebar-nav-overview data-target=site-overview>站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/linxi_icon.png alt=阳阳><p class=site-author-name itemprop=name>阳阳</p><p class="site-description motion-element" itemprop=description>再平凡的人也有属于他自己的梦想!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>142</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>35</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/yanyuLinxi target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>GitHub</a></span>
<span class=links-of-author-item><a href=https://space.bilibili.com/19237450 target=_blank title=哔哩哔哩><i class="fa fa-fw fa-globe"></i>哔哩哔哩</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0>论文阅读笔记</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python%E7%9B%B8%E5%85%B3%E5%BA%93%E5%AD%A6%E4%B9%A0>Python相关库学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90>异常行为分析</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7>深度学习辅助工具</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/kaggle>Kaggle</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%BA%93>机器学习相关库</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/java%E5%AD%A6%E4%B9%A0>Java学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/insider-threat>Insider threat</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/leetcode%E5%AD%A6%E4%B9%A0>Leetcode学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/spark>Spark</a></li></ul></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#导入数据>导入数据</a></li><li><a href=#特征工程>特征工程</a><ul><li><a href=#异常特征处理>异常特征处理</a></li><li><a href=#处理缺失值>处理缺失值</a></li><li><a href=#构造新特征>构造新特征</a></li><li><a href=#处理特征用于其他模型>处理特征用于其他模型</a></li></ul></li></ul></nav></div></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span><span class=copyright-author>阳阳的人间旅游日记</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.81.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv><i class="fa fa-user"></i><span class=busuanzi-value id=busuanzi_value_site_uv></span></span><span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i><span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href style=font-weight:700 target=_blank></a></span><span class=separator-line>/</span>
<span class=license-num><a href target=_blank></a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i><span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript src=/js/search.js></script><script type=text/javascript src=/js/affix.js></script><script type=text/javascript src=/js/scrollspy.js></script><script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script><script type=text/javascript>$(function(){$('.post-body').viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script><script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script></body></html>