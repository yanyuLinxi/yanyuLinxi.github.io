<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>CodeBert a Pretrained Model for Programming and Natural Languages - 阳阳的人间旅游日记</title><meta name=keywords content="博客,程序员,思考,读书,笔记,技术,分享"><meta name=author content="阳阳"><meta property="og:title" content="CodeBert a Pretrained Model for Programming and Natural Languages"><meta property="og:site_name" content="阳阳的人间旅游日记"><meta property="og:image" content="/img/author.jpg"><meta name=title content="CodeBert a Pretrained Model for Programming and Natural Languages - 阳阳的人间旅游日记"><meta name=description content="欢迎来到临溪的博客站，个人主要专注于机器学习、深度学习的相关研究。在这里分享自己的学习心得。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i><a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span><span class=site-title>阳阳的人间旅游日记</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>让我们消除隔阂的，不是无所不知的脑袋，而是手拉手，坚决不放弃的那颗心</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span><span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://yanyulinxi.github.io/post/paperreading/codebert-a-pretrained-model-for-programming-and-natural-languages/ itemprop=url>CodeBert a Pretrained Model for Programming and Natural Languages</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i><span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2022-04-06">2022-04-06</time></span>
<span class=post-category>&nbsp; | &nbsp;
<i class="fa fa-folder-o fa-fw"></i><span class=post-meta-item-text>分类：</span>
<span itemprop=about itemscope itemtype=https://schema.org/Thing><a href=/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0 itemprop=url rel=index style=text-decoration:underline><span itemprop=name>论文阅读笔记</span></a>
&nbsp;</span></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i><span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>1590 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i><span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>4分钟</span></span>
<span id=/post/paperreading/codebert-a-pretrained-model-for-programming-and-natural-languages/ class=leancloud_visitors data-flag-title="CodeBert a Pretrained Model for Programming and Natural Languages">|
<i class="fa fa-binoculars fa-fw"></i><span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><h2 id=1-综述翻译>1. 综述翻译</h2><p>我们展示了 CodeBERT，一种用于编程语言 (PL) 和自然语言 (NL) 的双峰预训练模型。 CodeBERT 学习支持下游 NL-PL 应用程序的通用表示，例如自然语言代码搜索、代码文档生成等。我们使用基于 Transformer 的神经架构开发 CodeBERT，并使用包含预训练的混合目标函数对其进行训练替换令牌检测的任务，即检测从生成器中采样的似是而非的替代方案。这使我们能够利用 NL-PL 对的“双峰”数据和“单峰”数据，前者为模型训练提供输入标记，而后者有助于学习更好的生成器。我们通过微调模型参数在两个 NL-PL 应用程序上评估 CodeBERT。结果表明，CodeBERT 在自然语言代码搜索和代码文档生成方面都取得了最先进的性能。此外，为了研究在 CodeBERT 中学习了什么类型的知识，我们构建了一个用于 NL-PL 探测的数据集，并在预训练模型的参数固定的零样本设置中进行评估。结果表明，CodeBERT 在 NL- 上的表现优于以前的预训练模型PL 探测.1</p><h3 id=11-发表于>1.1 发表于</h3><p>EMNLP 2020</p><h2 id=2-tag>2. Tag</h2><p>代码语义; Bert; Code Semantic; CodeBert; Natural Language; Multi-tasks;</p><h2 id=3-任务描述>3. 任务描述</h2><p>特征提取模型，用于提取语义特征，并不针对某个任务。</p><p>CodeBERT是一种可处理双模态数据（编程语言PL和自然语言NL）的预训练模型，支持下游 NL-PL 应用程序(如自然语言代码搜索、代码文档生成等)的通用表示。</p><p>CodeBERT基于 Bert 的架构开发，混合目标函数结合了替换标记检测的预训练任务。</p><p>在两个 NL-PL 下游任务上微调，结果显示在自然语言代码搜索和代码文档生成任务上达到了SOTA。此外，文章还构建了一个用于 NL-PL 探测的数据集，并在预训练模型的参数固定的零样本设置中进行了评估。</p><h2 id=4-方法>4. 方法</h2><p>输入： [CLS], w1, w2, …wn,[SEP],c1, c2, …, cm,[EOS]
w为NL单词序列，c为PL token序列。[CLS]为两个片段前的特殊token。
输出：自然语言和代码中每个token的上下文向量表示，以及[CLS]的表示，作为聚合序列的表示</p><h3 id=预训练任务>预训练任务：</h3><p>数据：</p><ol><li>双峰NL-PL 对是指类似下面的自然语言-程序语言对，即带有配对文档的单独函数，语料一般以json行格式文件保存，一行是一个json对象：</li></ol><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json>{
  <span style=color:green;font-weight:700>&#34;nl&#34;</span>: <span style=color:#b44>&#34;Increment this vector in this place. con_elem_sep double[] vecElement con_elem_sep double[] weights con_func_sep void add(double)&#34;</span>,
  <span style=color:green;font-weight:700>&#34;code&#34;</span>: <span style=color:#b44>&#34;public void inc ( ) { this . add ( 1 ) ; }&#34;</span>
}
</code></pre></div><ol start=2><li>单峰数据是指没有成对自然语言文本的单独函数代码和没有成对代码的自然语言</li></ol><p>任务：</p><ol><li>MLM任务 (Masked Language Modeling)<ol><li>对NL-PL双峰数据对应用MLM，即选择随机位置的NL和PL mask，用特殊token [MASK]代替</li><li>MLM的目标是预测被mask的token。鉴别器$p^{D_i}$预测第i个单词为masked的token的概率</li><li>$L _ { M L M }( \theta ) = \sum _ { i \in m^w \cup m^c } - \log p ^ { D _ { 1 } } ( x _ { i } | w ^ { m a s k e d } , { c ^ { m a s k e d } } )$</li><li>公式意思就是针对被mask的值，$p^D$从一个大的字典库中预测出他们。</li></ol></li><li>RTD任务（Replaced Token Detection)<ol><li>使用双峰数据。训练时同时使用双峰数据和单峰数据，有两个数据生成器$p^{G_w}, p^{G_c}$，一个生成NL，一个生成PL，用于选择随机掩蔽位置。生成器随机找一个位置使用生成的token进行代替。</li><li>鉴别器$p^{D_2}$鉴别是否正好生成了原始单词，即第i个单词为原始单词的概率。</li><li>$L _ { R T D } ( \theta ) = \sum _ { i = 1 } ^ { | w | + | c | } ( \delta ( i ) \log p ^ { D_2 } ( x ^ { \operatorname { corrupt} } , i ) + ( 1 - \delta ( i ) ) ( 1 - \log p ^ { D_2 } ( x ^ { \operatorname { corrupt}} , i ))$</li><li>就是针对每个单词判断它为原始词的概率。</li></ol></li><li>两个任务的组合：<ol><li>$$m i n L_{MLM} ( \theta ) + L _ { R T D } ( \theta )$$</li></ol></li></ol><h4 id=数据处理>数据处理</h4><ol><li>1)每个项目应该被至少一个其他项目使用，(2)每个文档被截断到第一段（图中红色表示），(3)小于三个标记的文档被删除，(4)小于三行的函数被删除，(5)带有子字符串“test”的函数名被删除。图13给出了一个数据示例。</li></ol><h3 id=实验任务>实验任务</h3><ol><li>自然语言代码搜索<ol><li>微调</li><li>不用微调</li></ol></li><li>代码文档生成<ol><li>微调</li><li>不用微调</li></ol></li></ol><h2 id=5-解决了什么问题贡献>5. 解决了什么问题（贡献）</h2><h2 id=6-实验结果>6. 实验结果</h2><h2 id=7-如何想到该方法>7. 如何想到该方法</h2><h2 id=8-我能否想到该方法>8. 我能否想到该方法</h2><h2 id=9-创新点是什么>9. 创新点是什么</h2><h2 id=10-如何用于本专业>10. 如何用于本专业</h2><h2 id=11-该方案还存在的问题>11. 该方案还存在的问题</h2><h2 id=12-注释>12. 注释</h2></div><footer class=post-footer><div class=post-tags><a href=/tags/%e8%ae%ba%e6%96%87%e9%98%85%e8%af%bb%e7%ac%94%e8%ae%b0 rel=tag title=论文阅读笔记>#论文阅读笔记#</a></div><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>CodeBert a Pretrained Model for Programming and Natural Languages</p><p style=word-break:break-all><span>链接：</span>
https://yanyulinxi.github.io/post/paperreading/codebert-a-pretrained-model-for-programming-and-natural-languages/</p><p><span>作者：</span>阳阳</p><p><span>邮箱：</span>yanyulinxi@qq.com</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick="var qr=document.getElementById('QR');qr.style.display==='none'?qr.style.display='block':qr.style.display='none'">
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=https://yanyulinxi.github.io/post/paperreading/graphcodebert-pretraining-code-representation-with-data-flow/ rel=next title="GraphCodeBert PreTraining Code Representation With Data Flow"><i class="fa fa-chevron-left"></i>GraphCodeBert PreTraining Code Representation With Data Flow</a></div><div class="post-nav-prev post-nav-item"><a href=https://yanyulinxi.github.io/post/paperreading/ordermatters-semantic-aware-neural-networks/ rel=prev title="OrderMatters Semantic Aware Neural Networks">OrderMatters Semantic Aware Neural Networks
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>文章目录</li><li class=sidebar-nav-overview data-target=site-overview>站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/linxi_icon.png alt=阳阳><p class=site-author-name itemprop=name>阳阳</p><p class="site-description motion-element" itemprop=description>再平凡的人也有属于他自己的梦想!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>129</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>34</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/yanyuLinxi target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>GitHub</a></span>
<span class=links-of-author-item><a href=https://space.bilibili.com/19237450 target=_blank title=哔哩哔哩><i class="fa fa-fw fa-globe"></i>哔哩哔哩</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0>论文阅读笔记</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90>异常行为分析</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python%E7%9B%B8%E5%85%B3%E5%BA%93%E5%AD%A6%E4%B9%A0>Python相关库学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7>深度学习辅助工具</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E5%BA%93>机器学习相关库</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/java%E5%AD%A6%E4%B9%A0>Java学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/insider-threat>Insider threat</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/leetcode%E5%AD%A6%E4%B9%A0>Leetcode学习</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/%E7%BE%8E%E9%A3%9F%E7%82%B9%E8%AF%84>美食点评</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/rnn>Rnn</a></li></ul></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#1-综述翻译>1. 综述翻译</a><ul><li><a href=#11-发表于>1.1 发表于</a></li></ul></li><li><a href=#2-tag>2. Tag</a></li><li><a href=#3-任务描述>3. 任务描述</a></li><li><a href=#4-方法>4. 方法</a><ul><li><a href=#预训练任务>预训练任务：</a></li><li><a href=#实验任务>实验任务</a></li></ul></li><li><a href=#5-解决了什么问题贡献>5. 解决了什么问题（贡献）</a></li><li><a href=#6-实验结果>6. 实验结果</a></li><li><a href=#7-如何想到该方法>7. 如何想到该方法</a></li><li><a href=#8-我能否想到该方法>8. 我能否想到该方法</a></li><li><a href=#9-创新点是什么>9. 创新点是什么</a></li><li><a href=#10-如何用于本专业>10. 如何用于本专业</a></li><li><a href=#11-该方案还存在的问题>11. 该方案还存在的问题</a></li><li><a href=#12-注释>12. 注释</a></li></ul></nav></div></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span><span class=copyright-author>阳阳的人间旅游日记</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.81.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv><i class="fa fa-user"></i><span class=busuanzi-value id=busuanzi_value_site_uv></span></span><span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i><span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href style=font-weight:700 target=_blank></a></span><span class=separator-line>/</span>
<span class=license-num><a href target=_blank></a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i><span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script><script type=text/javascript src=/js/search.js></script><script type=text/javascript src=/js/affix.js></script><script type=text/javascript src=/js/scrollspy.js></script><script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script><script type=text/javascript>$(function(){$('.post-body').viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script><script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script></body></html>