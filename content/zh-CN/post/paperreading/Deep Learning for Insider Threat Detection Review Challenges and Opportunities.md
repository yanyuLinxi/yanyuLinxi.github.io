---
title: "Deep Learning for Insider Threat Detection Review Challenges and Opportunities"
date: 2021-09-16T18:47:40+08:00
tags : [
    "论文阅读笔记",
    "异常行为分析",
    "survey",
]
categories : [
    "论文阅读笔记",
]
series : []
aliases : []
draft: false
math: true
---

# 目录： <!-- omit in toc -->
- [1. 综述翻译](#1-综述翻译)
- [2. Tag](#2-tag)
- [3. 任务描述](#3-任务描述)
- [4. 方法](#4-方法)
  - [Deep Feedforward Neural Network](#deep-feedforward-neural-network)
  - [RecurrentNeuralNetwork.](#recurrentneuralnetwork)
  - [Convolutional Neural Network](#convolutional-neural-network)
  - [GraphNeuralNetwork.](#graphneuralnetwork)
  - [Challenges](#challenges)
- [5. 解决了什么问题（贡献）](#5-解决了什么问题贡献)
- [6. 实验结果](#6-实验结果)
- [7. 如何想到该方法](#7-如何想到该方法)
- [8. 我能否想到该方法](#8-我能否想到该方法)
- [9. 创新点是什么](#9-创新点是什么)
- [10. 如何用于本专业](#10-如何用于本专业)
- [11. 该方案还存在的问题](#11-该方案还存在的问题)
- [12. 注释](#12-注释)

# 1. 综述翻译

内部威胁作为网络空间中最具挑战性的威胁之一，通常会给组织造成重大损失。虽然安全和数据挖掘社区对内部威胁检测问题已经研究了很长时间，但传统的基于机器学习的检测方法严重依赖特征工程，难以准确捕捉内部人员和普通用户之间的行为差​​异，原因是与底层数据特征相关的各种挑战，例如高维、复杂、异构、稀疏、缺乏标记的内部威胁，以及内部威胁的微妙和适应性。先进的深度学习技术提供了一种从复杂数据中学习端到端模型的新范式。在这个简短的调查中，我们首先介绍一个常用的内部威胁检测数据集，并回顾有关此类研究的深度学习的最新文献。现有研究表明，与传统的机器学习算法相比，深度学习模型可以提高内部威胁检测的性能。然而，应用深度学习来进一步推进内部威胁检测任务仍然面临一些限制，例如缺乏标记数据、自适应攻击。然后，我们讨论这些挑战，并提出有可能应对挑战并进一步提高深度学习性能的未来研究方向。
内部威胁检测。

2021- Computer & Security  网络与信息安全的B会。
# 2. Tag

database insider threats; insider attack; deep learning

# 3. 任务描述

在协调中心 (CERT/CC) 中，恶意内部人员被定义为“已经或已经授权访问组织的网络、系统或数据的现任或前任员工、承包商或业务合作伙伴，并故意超出或故意使用该组织的网络、系统或数据。以对组织信息或信息系统的机密性、完整性或可用性产生负面影响的方式访问。”

最近的一项调查根据检测中使用的策略和特征将内部威胁检测技术进一步分为 9 类：（1）基于异常的方法，（2）基于角色的访问控制，（3）基于场景的技术，（4） 诱饵文件和蜜罐技术，(5) 使用心理因素进行风险分析，(6) 使用工作流进行风险分析，(7) 改进网络防御，(8) 通过访问控制改进防御，以及 (9) 过程控制以劝阻内部人员 .

异常检测是识别与所有其他实例不同的实例，这是欺诈检测、入侵检测和视频监控等多种应用的重要问题[13]。异常在数据挖掘和统计文献中被称为异常、异常或异常值，粗略地说，内部威胁可以被视为一种异常。

# 4. 方法

最近的一项调查 [12] 将深度分类基于标签的可用性将基于学习的异常检测分为三组，即监督、半监督和无监督的深度异常检测。在某些情况下，当正常和异常数据都可用时，有监督的深度异常检测方法被提议用于二元或多类分类 [10, 11]。一个更常见的场景是很容易收集到很多正常样本而只有少量异常样本可用，因此可以通过利用正常样本分离异常值来采用半监督深度异常检测[1, 67, 85 ]。当没有标记数据可用时，基于数据样本的内在属性，应用无监督的深度异常检测来检测异常

有一个数据集：卡内基梅隆大学软件工程研究所的 CERT 部门维护着一个包含 1000 多个内部威胁真实案例研究的数据库，并使用包含叛徒实例和伪装活动的场景生成了一系列合成内部威胁数据集。 CERT 数据集包含记录计算机的官方日志文件 -。他们进一步将常用的11个数据分为五类：基于伪装者、基于叛徒、杂项恶意、替代伪装者和基于识别/认证。

深度学习在内部威胁检测方面的潜在优势，可以总结如下。

+ 表征学习。深度学习模型最显着的优势在于能够自动发现检测所需的特征。网络空间中的用户行为是复杂且非线性的。手动设计的功能很难捕获用户行为信息，而且效率低下。同时，具有浅层结构的学习模型，如 HMM 和 SVM，是相对简单的结构，只有一层用于将原始特征转换为可用于检测的高级抽象。这些浅层模型对于解决许多约束良好的问题是有效的，但是能力有限的浅层模型很难对复杂的用户行为数据进行建模。相比之下，深度学习模型能够利用深度非线性模块通过通用学习程序来学习表示。因此，使用深度学习模型来捕捉复杂的用户行为并精确检测用户的意图，尤其是那些恶意的意图是很自然的。
+ 序列建模。 深度学习模型，例如循环神经网络 (RNN) 和新提出的 Transformer，在对序列数据（例如视频、文本和语音）进行建模方面表现出良好的性能 [27, 70]。 由于将审计数据中记录的用户活动表示为顺序数据是很自然的，因此利用 RNN 或 Transformer 捕获复杂用户行为的显着信息具有提高内部威胁检测性能的巨大潜力。
+ 异构数据组合。 深度学习模型在融合的任务上也取得了出色的表现
异构数据，例如图像字幕 [16, 36]。 对于内部威胁检测，除了将用户活动数据建模为序列之外，其他信息，例如组织中的用户配置文件信息和用户结构信息，也很关键。 与仅使用单一类型的数据相比，结合所有用于内部威胁检测的有用数据有望获得更好的性能。 与传统的机器学习方法相比，深度学习模型更强大地结合异构数据进行检测。

## Deep Feedforward Neural Network
[48] Anomaly-based Insider Threat Detection using Deep Autoencoders 使用深度自动编码器来检测内部威胁。深度自动编码器由编码器和解码器组成，其中编码器将输入数据编码为隐藏表示，而解码器旨在基于隐藏表示重构输入数据。深度自动编码器的目标是使重构输入接近原始输入。由于组织中的大多数活动都是良​​性的，带有内部威胁的输入应该具有相对较高的重构误差。因此，深度自编码器的重构误差可以作为异常分数来识别内部威胁。利用自动编码器结构的另一个想法是，在根据重构误差学习隐藏表示之后，将一类分类器（例如一类 SVM）应用于学习到的隐藏表示以识别内部威胁 [45]

## RecurrentNeuralNetwork.

因此，已经提出了许多基于 RNN 的方法来模拟用户活动 [51, 69, 79, 80] 以进行内部威胁检测。基本思想是训练一个 RNN 模型来预测用户的下一个活动或活动周期。只要预测结果和用户的真实活动没有显着差异，我们就认为用户遵循了正常的行为。否则，用户活动是可疑的

[69] Deep Learning for Unsupervised Insider Threat Detection in Struc- tured Cybersecurity Data Streams 提出了一个堆叠的 LSTM 结构来捕获一天中的用户活动，并采用用户活动的负对数似然作为异常分数来识别恶意会话。 [80]Insider_Threat_Detection_via_Hierarchical_Neural_Temporal_Point_Processes 不是仅使用活动类型（例如，网络访问或文件上传）进行内部威胁检测，而是提出了一种分层神经时间点过程模型来捕获用户会话中的活动类型和时间信息，然后得出异常分数基于预测结果与实际活动在类型和时间方面的差异。

## Convolutional Neural Network

最近一项关于内部威胁检测的研究通过分析鼠标生物行为特征提出了一种基于 CNN 的用户身份验证方法 [35]An Insider Threat Detection Approach Based on Mouse Dynamics and Deep Learning。所提出的方法将计算机上的用户鼠标行为表示为图像。如果发生身份盗用攻击，用户的鼠标行为将与合法用户不一致。因此，将 CNN 模型应用于基于鼠标行为生成的图像，以识别潜在的内部威胁。

## GraphNeuralNetwork.

最近的工作 [37]Anomaly Detection with Graph Convolutional Networks for Insider Threat and Fraud Detection. 采用 GCN 模型来检测内部人员。由于组织中的用户经常通过电子邮件或在同一设备上的操作相互联系，因此使用图结构来捕获用户之间的相互依赖关系是很自然的。除了以结构信息的邻接矩阵作为输入外，GCN还结合了丰富的用户画像信息作为节点的特征向量。在基于图结构应用卷积层进行信息传播后，GCN 采用交叉熵作为目标函数来预测图中的恶意节点（用户）。受图嵌入方法的启发，[47]Log2vec A Heterogeneous Graph Embedding Based Approach 中的研究提出 log2vec 来检测恶意活动。 Log2vec 首先通过将审计数据中的各种活动表示为节点，将活动之间的丰富关系表示为边来构建异构图，然后训练可以对活动关系进行编码的节点嵌入。最后，通过在节点嵌入上应用聚类算法，log2vec 能够将恶意和良性活动分成不同的集群并识别恶意活动。

## Challenges

1. Extremely Unbalanced Data. 与良性活动相比，来自内部人员的恶意活动在现实场景中极为罕见。 因此，内部威胁数据集是一个不平衡的数据集，这是训练深度学习模型的一大挑战。 一般来说，由大量参数组成的深度学习模型需要大量标记数据才能正确训练。 但是，在现实中收集大量的恶意内部人员是不可行的。 如何利用现有的小样本正确训练深度学习模型对于内部威胁检测任务至关重要。
2. Temporal Information in Attacks. 大多数现有的内部威胁检测方法只关注活动类型信息，例如将文件复制到可移动磁盘或浏览网页。 然而，仅仅根据用户进行的活动类型来检测攻击是不够的，因为相同的活动可能是良性的，也可能是恶意的。 一个简单的例子是，工作时间复制文件看起来很正常，但半夜复制文件却很可疑。 时间信息在分析用户行为以识别那些恶意威胁方面起着重要作用，如何合并这些时间信息具有挑战性
3. Heterogeneous Data Fusion. 除了时间信息，利用各种数据源并融合此类异构数据对于提高内部威胁检测也至关重要。 例如，在日常工作中处理文件的用户预见到他的潜在裁员并且有目的地将凭证文件复制到可移动磁盘的活动。 在这种情况下，考虑用户资料（即心理测量分数）或用户交互数据可能有助于识别潜在的内部威胁。
4. Subtle Attacks. 目前，大部分现有工作都将内部威胁检测任务视为异常检测任务，通常将异常样本建模为分布外样本。 现有模型通常在来自良性用户的样本上进行训练，然后应用于识别与观察到的良性样本不同的内部人员。 推导出阈值或异常分数来量化内部人员和良性用户之间的差异。 但是，在现实中，我们不能期望内部人员进行恶意活动的模式发生重大变化。 为了逃避检测，内部威胁是微妙且难以察觉的，这意味着内部人员和良性用户在特征空间中很接近。 传统的异常检测方法无法检测接近良性用户的内部人员。
5. Adaptive Threats. 内部人员总是改进攻击策略以逃避检测。 然而，基于学习的模型在训练后无法检测新的攻击类型。 当观察到新类型的攻击时，再次从头开始训练模型是低效的。 首先，通常需要一些时间来收集足够的样本来训练模型。 更重要的是，再训练策略不能确保及时发现和预防。 设计一个可以自适应地提高内部威胁检测性能的模型是一项重要且具有挑战性的任务。
6. Fine-grainedDetection. 现有的基于深度学习的方法通常会检测包含恶意活动的恶意会话。 然而，用户通常在一个会话中进行大量的活动。 这种粗粒度的检测面临着难以及时检测的问题。 因此，如何识别细粒度的恶意子序列或确切的恶意活动对于内部威胁检测很重要。 这也是一项非常具有挑战性的任务。 这是因为我们可以从每个活动中利用的信息非常有限，即我们只观察用户何时以及进行了哪些活动。 没有足够的信息，很难实现细粒度的内部威胁检测
7. EarlyDetection. 当前的方法侧重于内部威胁检测，这意味着恶意活动已经发生并且已经给组织造成了重大损失。 因此，一个新兴的话题是如何实现内部威胁的早期检测，即在潜在的恶意活动实际发生之前检测它们。 提出了几种通过使用通用 IT 安全机制来防御内部威胁的方法 [3, 66]，但没有基于学习的方法来实现早期检测。 主动识别在不久的将来很有可能进行恶意活动的用户至关重要，以便组织可以提前进行干预以防止或减少损失。
8. Explainability. 深度学习模型通常被视为黑匣子。 尽管深度学习可以在许多领域取得可观的表现，但模型工作的原因仍然没有得到充分利用。当员工被检测为内部人员时，了解模型做出此类预测的原因至关重要，因为员工通常是最重要的 组织中的宝贵资产。 特别是，深度学习模型无法在内部威胁检测上达到 100% 的准确度。 误报案例（将良性用户错误分类为内部人员）会严重影响员工对组织的忠诚度。 因此，模型的可解释性是向领域专家提供模型洞察力的关键，以便可以高可信度地执行进一步的操作。
9.  Lack of Testbed. 
10. Lack of Practical Evaluation Metrics. 采用常用的分类指标，如真阳性率（TPR）、假阳性率（FPR）、准确率和召回率来评估内部威胁检测的性能。基于 TPR 和 FPR，可以通过将 FPR 和 TPR 分别设置为 x 和 y 轴来绘制接收器操作特征 (ROC) 曲线，该曲线表示真阳性和假阳性之间的权衡。理想情况下，我们期望内部威胁检测算法可以实现 TPR 为 1，FPR 为 0。目前，在文献中，ROC 曲线下面积（AUC）分数被广泛用于比较不同检测算法的性能 [45， 47、48、51、80]。另一个指标是精度-召回率 (PR) 曲线，它是召回率和精度作为 x 和 y 轴的图，用于评估不平衡的数据分类。与 ROC-AUC 相比，PR-AUC 在评估内部威胁检测算法方面可能更有用，因为 PR 曲线更关注分类器在少数类上的性能。然而，由于内部人员的数量极少以及相应的恶意活动，目前尚不清楚 ROC-AUC 或 PR-AUC 是否适用于评估内部威胁检测。例如，来自不同检测算法的 ROC-AUC 值通常很接近 [48,51,80]，这意味着很难根据 ROC-AUC 值确定更好的模型。

# 5. 解决了什么问题（贡献）

# 6. 实验结果

# 7. 如何想到该方法

# 8. 我能否想到该方法

# 9. 创新点是什么

# 10. 如何用于本专业

# 11. 该方案还存在的问题

# 12. 注释
