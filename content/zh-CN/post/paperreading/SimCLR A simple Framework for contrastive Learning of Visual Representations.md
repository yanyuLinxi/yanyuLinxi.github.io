---
title: "SimCLR a Simple Framework for Contrastive Learning of Visual Representations"
date: 2021-11-18T16:57:54+08:00
tags : [
    "论文阅读笔记",
]
categories : [
    "论文阅读笔记",
]
series : []
aliases : []
draft: false
---

# 目录： <!-- omit in toc -->
- [1. 综述翻译](#1-综述翻译)
  - [1.1 发表于](#11-发表于)
- [2. Tag](#2-tag)
- [3. 任务描述](#3-任务描述)
- [4. 方法](#4-方法)
- [5. 解决了什么问题（贡献）](#5-解决了什么问题贡献)
- [6. 实验结果](#6-实验结果)
- [7. 如何想到该方法](#7-如何想到该方法)
- [8. 我能否想到该方法](#8-我能否想到该方法)
- [9. 创新点是什么](#9-创新点是什么)
- [10. 如何用于本专业](#10-如何用于本专业)
- [11. 该方案还存在的问题](#11-该方案还存在的问题)
- [12. 注释](#12-注释)

# 1. 综述翻译

本文介绍了 SimCLR：一个用于视觉表示对比学习的简单框架。我们简化了最近提出的对比自监督学习算法，而不需要专门的架构或存储库。为了了解是什么使对比预测任务能够学习有用的表示，我们系统地研究了我们框架的主要组成部分。我们表明（1）数据增强的组合在定义有效的预测任务中起着关键作用，（2）在表示和对比损失之间引入可学习的非线性转换大大提高了学习表示的质量，以及（3）对比学习与监督学习相比，它受益于更大的批量和更多的训练步骤。通过结合这些发现，我们能够大大优于以前在 ImageNet 上进行自监督和半监督学习的方法。在 SimCLR 学习的自监督表示上训练的线性分类器实现了 76.5% 的 top-1 准确率，相对于之前的最新技术水平提高了 7%，与监督 ResNet-50 的性能相匹配。当仅对 1% 的标签进行微调时，我们实现了 85.8% 的 top-5 准确率，在标签数量减少 100 倍的情况下优于 AlexNet。

## 1.1 发表于

ICML 2020.

分析文章：
https://mp.weixin.qq.com/s/tV5eSx73fzMovq0d7Jvu9Q
https://zhuanlan.zhihu.com/p/258958247

# 2. Tag

# 3. 任务描述

# 4. 方法

# 5. 解决了什么问题（贡献）

# 6. 实验结果

# 7. 如何想到该方法

# 8. 我能否想到该方法

# 9. 创新点是什么

# 10. 如何用于本专业

# 11. 该方案还存在的问题

# 12. 注释
