---
title: "Progress in Outlier Detection Techniques a Survey"
date: 2021-10-07T16:20:04+08:00
tags : [
    "论文阅读笔记",
]
categories : [
    "论文阅读笔记",
]
series : []
aliases : []
draft: false
---

# 目录： <!-- omit in toc -->
- [1. 综述翻译](#1-综述翻译)
  - [1.1 发表于](#11-发表于)
- [2. Tag](#2-tag)
- [3. 任务描述](#3-任务描述)
- [4. 方法](#4-方法)
  - [基于密度的方法](#基于密度的方法)
  - [基于统计的方法](#基于统计的方法)
    - [基于参数的](#基于参数的)
      - [GAUSSIAN MIXTURE MODEL METHODS](#gaussian-mixture-model-methods)
      - [REGRESSION METHODS](#regression-methods)
    - [非参数方法](#非参数方法)
    - [其他统计方法](#其他统计方法)
    - [优缺点](#优缺点)
  - [基于距离的方法](#基于距离的方法)
  - [基于聚类的方法](#基于聚类的方法)
  - [基于聚类的](#基于聚类的)
- [5. 解决了什么问题（贡献）](#5-解决了什么问题贡献)
- [6. 实验结果](#6-实验结果)
- [7. 如何想到该方法](#7-如何想到该方法)
- [8. 我能否想到该方法](#8-我能否想到该方法)
- [9. 创新点是什么](#9-创新点是什么)
- [10. 如何用于本专业](#10-如何用于本专业)
- [11. 该方案还存在的问题](#11-该方案还存在的问题)
- [12. 注释](#12-注释)

# 1. 综述翻译

检测异常值是一个重要问题，已在各个研究和应用领域进行了研究。研究人员继续设计稳健的方案，以提供有效检测异常值的解决方案。在本次调查中，我们对 2000 年至 2019 年异常值检测方法的进展进行了全面而有组织的回顾。首先，我们提供了异常值检测的基本概念，然后将它们从不同的异常值检测技术中分类为不同的技术，例如距离- 、聚类、密度、集成和基于学习的方法。在每个类别中，我们介绍了一些最先进的异常值检测方法，并在性能方面进一步详细讨论它们。其次，我们描述了它们的优缺点和挑战，为研究人员提供每种技术的简要概述，并推荐解决方案和可能的研究方向。本文介绍了异常值检测技术的当前进展，并提供了对不同异常值检测方法的更好理解。最后的开放研究问题和挑战将为研究人员提供未来异常检测方法的清晰路径

## 1.1 发表于

IEEE Access 

# 2. Tag

# 3. 任务描述

# 4. 方法

尽管在定义异常值时存在模糊性和复杂性，但通常可以将其描述为与其他数据点显着不同的数据点或不模仿其他点的预期典型行为的点 [5]。与异常值相反的数据点称为内点。

+ 基于统计的方法 基于统计的技术在标记或识别异常值方面的基本思想取决于与分布模型的关系。这些方法通常分为两大类——参数方法和非参数方法。
• 基于距离的方法。基于距离的检测算法的基本原理侧重于观测之间的距离计算。一个点被视为离其附近邻居很远的离群点。
• 基于密度的方法。这些方法的核心原理是在低密度区域可以找到异常值，而在密集邻域中可以找到内部值。
• 基于聚类的方法。基于聚类的技术的关键思想是应用标准聚类技术从给定数据中检测异常值。异常值被认为是不在任何大型或密集集群内或附近的观测值。
• 基于图的方法 基于图的方法基于使用图技术来有效地捕获互连实体的相互依赖性以识别异常值。
• 基于集成的方法 集成方法侧重于组合不同模型的结果以生成更稳健的模型以有效检测异常值的想法。它们有助于回答异常值是否应该基于线性模型、基于距离或其他类型的模型的问题。
• 基于学习的方法 基于学习的方法，例如主动学习和深度学习，其基本思想是通过应用这些学习方法来学习不同的模型来检测异常值。

## 基于密度的方法

基于密度的离群点检测方法的核心原理是在低密度区域可以找到离群点，而假设非离群点（inliers）出现在密集的邻域中。与其最近的邻居有很大不同的对象，即那些远离最近邻居的对象，被标记并始终被视为异常值。他们将本地点的密度与其本地邻居密度进行比较。与基于距离的方法相比，在基于密度的异常值检测方法中，应用了更复杂的机制来对异常值进行建模。

提出了局部异常因子（LOF）方法，这是第一个基本的松散相关的基于密度的聚类异常值检测方法之一。该技术利用了 k 最近邻。在每个点的 KNN 集中，LOF 利用局部可达性密度 (lrd) 并将其与该 KNN 集的每个参与者的邻居的可达性密度进行比较。

Tang 等人介绍了对 LOF [8] 和简化的 LOF [79] 的改进。 [80]，他们称之为基于连接的离群因子（COF）。 该方法与 LOF 非常相似，唯一的区别是计算记录密度估计的方式。 COF 使用链接距离作为最短路径来估计邻居的局部密度，而 LOF 使用欧几里得距离来选择 K-最近邻居。 这种方法的缺点是对数据分布的间接假设，这会导致不正确的密度估计。 作者提出的关键思想是基于将“低密度”与“孤立性”区分开来。 孤立性被定义为一个物体与其他物体的连通程度。

在基于密度的方法中，使用的密度估计是非参数的； 它们不依赖于假设的分布来拟合数据。

在最广为人知的基于密度的方法之一 LOF [8] 中，必须注意的是，在局部异常值不显着的异常值检测过程中，该算法可能会产生大量误报。通常，由于基于密度的方法是非参数的，对于高维数据空间，样本量被认为太小 [27]

## 基于统计的方法
基于统计的方法通常分为两大类——参数方法和非参数方法。 两种方法的主要区别在于前者对给定数据中的底层分布模型有一个假设，并从已知数据中估计分布模型的参数。 后一种方法没有任何关于分布模型的先验知识的假设 [98]

我们将目前使用统计方法检测异常值的一些研究分为三类 - 参数方法、非参数方法和其他类型的统计技术。

### 基于参数的

#### GAUSSIAN MIXTURE MODEL METHODS
对于这种具有底层分布模型假设的方法，异常值检测采用的两种众所周知的方法是高斯混合模型和回归模型

高斯模型是用于检测异常值的最流行的统计方法之一。 在这个模型中，训练阶段使用最大似然估计 (MLE) 方法 [100] 来执行高斯分布的均值和方差估计。 在测试阶段，应用了一些统计不一致测试（箱线图、均值方差测试）。 杨等人。 [101]，介绍了一种具有全局最优 Exemplar-BasedGMM（高斯混合模型）的无监督异常值检测方法

可以降低这种计算复杂性的算法可以为未来的研究提供更大的可扩展性。 2015 年，为了更稳健的异常值检测方法，Tang 等人提出了使用具有局部保留投影的 GMM。 [102]。他们结合使用 GMM 和子空间学习在能量分解中进行稳健的异常值检测。在他们的方法中，子空间学习的局部保留投影（LPP）用于有效地保留邻域结构，然后揭示数据的内在流形结构。

[103] 主成分分析（PCA）方法。本研究解决了先前方法 LOF [8] 和 Tang 等人的研究空白

#### REGRESSION METHODS

多年来，使用回归技术进行异常值检测的一些标准方法包括使用马氏距离进行阈值处理、具有双平方权重的稳健最小二乘法、混合模型，然后是替代的振动贝叶斯回归方法 [26]


### 非参数方法
核密度估计方法：核密度估计 (KDE) 是一种用于检测异常值的常见非参数方法 [107]。 Latecki 等人在 [108] 中提出了一种使用核函数进行异常值检测的无监督方法。异常值检测过程是通过将每个点的局部密度与邻居的局部密度进行比较来执行的。

### 其他统计方法
如箱线图、修剪平均值、极端学生化偏差和狄克逊型检验 [40] .其中，Trimmed mean 更能抵抗异常值，而为了识别单个异常值，Extreme Studentized Deviate test 是正确的选择。 Dixon 型检验具有在样本量较小时表现良好的优点，因为无需假设数据的正态性。巴内特等人。

### 优缺点

+ 它们在数学上是可以接受的，并且一旦模型建立起来就有一个快速的评估过程。这是因为大多数模型都是以紧凑的形式制作的，并且在给定概率模型的情况下它们表现出改进的性能。
+ 这些模型通常适合定量实值数据集或一些定量有序数据分布。可以将序数数据更改为合适的值进行处理，从而缩短复杂数据的处理时间。
+ 即使仅限于特定问题，它们也更容易实现。

缺点，挑战和差距： 
+ 由于它们的依赖性和参数模型中分布模型的假设，由于缺乏有关潜在分布的先验知识，所产生的结果的质量对于实际情况和应用而言大多是不可靠的。
+ 由于大多数模型适用于单变量特征空间，因此它们通常不适用于多维场景。在处理多变量数据时，它们会产生很高的计算成本，这反过来又使大多数统计非参数模型成为实时应用程序的糟糕选择。
+ 在直方图技术中，多元数据的一个基本缺点是无法捕捉不同属性之间的相互作用。这是因为他们不能同时分析多个特征。一般来说，一些流行的统计方法不适用于处理非常高维的数据。需要设计统计技术来支持能够同时分析多个特征的高维数据。
+ 当面临维度增加的问题时，统计技术采用不同的方法。这会导致处理时间增加和误报发送数据的分布。

当捕获正确的分布模型时，基于统计的方法可以在异常值检测过程中有效。在一些现实生活中，例如，在传感器流分布中，没有可学习的先验知识。在这种情况下，当数据不遵循预定分布时，它可能变得不切实际。因此，非参数方法最有吸引力，因为它们不依赖于分布特征的假设。对于无法假设数据分布的大数据流也是如此。对于数据集中均匀分散的异常值，使用统计技术变得复杂。因此，参数方法不适用于大数据流，但对于非参数方法，它们适用。此外，定义标准分布的阈值以区分异常值具有更高的标记不准确概率。对于参数情况，使用高斯混合模型，

## 基于距离的方法

最常用的基于距离的异常值检测定义以局部邻域、k-最近邻 (KNN) [121] 和传统距离阈值的概念为中心。它与 k-最近邻分类不同。这些方法主要用于检测全局异常值。最初，搜索每条记录的 k 最近邻居，然后这些邻居用于计算异常值分数。他们主要检查给定对象邻域信息的性质，以确定它们是否靠近邻居或是否具有低密度

[76] 提出了一种基于局部距离的异常值检测方法，称为基于局部距离的异常值因子（LDOF）。他们的研究表明，与 LOF [8] 相比，在邻居大小范围内的性能有所提高。对成对距离计算的需求是 (O(k2))


它们简单易懂，因为它们大多不依赖于假设分布来拟合数据。
ii.在可扩展性方面，它们在多维空间中的扩展性更好，因为它们具有强大的理论基础，并且与统计方法相比，它们的计算效率更高。


缺点、挑战和差距： i．在高维空间方面，它们与基于统计和基于密度的方法有一些相似的缺点，因为它们的性能由于维数灾难而下降。数据中的对象通常具有离散的属性，这使得定义这些对象之间的距离具有挑战性。
ii.当使用基于距离的方法时，诸如邻域和 KNN 搜索之类的搜索技术在高维空间中是一项昂贵的任务。在大型数据集中，可扩展性也不具有成本效益。
三、现有的大多数基于距离的方法无法处理数据流的原因是它们难以维护局部邻域中的数据分布以及在数据流中寻找KNN。这是专门设计用于处理数据流的方法的一个例外。

## 基于聚类的方法
基于聚类的技术通常依赖于使用聚类方法来描述数据的行为。为此，包含比其他集群少得多的数据点的较小规模的集群被标记为异常值。需要注意的是，聚类方法与异常值检测过程不同。聚类方法的主要目的是识别聚类，而异常值检测是检测异常值。基于聚类的技术的性能高度依赖于聚类算法在捕获正常实例的聚类结构方面的有效性

+ 分区聚类方法：也称为基于距离的聚类算法。
ii. 分层聚类方法：它们将对象集划分为不同级别的组并形成树状结构。 为了分组到不同的级别，它们通常需要最大数量的集群。
三、 基于密度的聚类方法：它们不需要像分区方法那样初始给出聚类的数量； 比如K-Means。 给定集群的半径，他们可以将集群建模为密集区域。 密度聚类方法的一些例子
包括 DBSCAN [153] 和 DENCLUE [154]。
iv． 基于网格的聚类方法
v. 高维数据的聚类方法： CLIQUE [157], HPStream [158]

## 基于聚类的
与其他相关方法相比，基于集成的方法通常用于机器学习，因为它们的性能相对更好
近年来，已经引入了几种技术，包括：（I）Bagging [37] 和 boosting [184] 用于分类问题（ii）隔离森林 [192] 用于并行技术。 (iii) 对于顺序方法 [185] 和极限梯度提升异常值检测 (XGBOD) [183]​​ 和用于混合方法的袋装异常值表示集成 (BORE) [186]。

典型：
1. isolation Forest

# 5. 解决了什么问题（贡献）

+ 我们介绍了不同的最新异常值定义、不同的种类、原因、当代检测和处理过程，以及最新的挑战和应用领域。与其他调查不同，我们添加了需要更多关注的新应用领域。 
+ 我们扩展了异常值检测算法的类别，并在之前的调查中增加了不同的方法。我们介绍最先进的算法，讨论它们并突出它们的优点和缺点。我们主要引用和讨论在大多数重要调查 [26]、[33] 之后所做的最新研究。
+ 与之前的调查相比，我们通过介绍最近方法的优缺点、公开挑战和不足，显着扩展了对每个不同类别的讨论。我们还总结了一些最先进算法的性能、解决的问题、缺点和可能的解决方案。
+ 我们提出了一些评估异常值检测算法的当代开放挑战。然后我们介绍了标准工具和一些通常用于异常值检测研究的基准数据集。我们通过讨论 OD 工具选择和选择合适数据集的挑战来扩展我们的讨论。
+ 我们确定了一些挑战，并最终为未来的研究推荐了一些可能的研究方向。



# 6. 实验结果

# 7. 如何想到该方法

# 8. 我能否想到该方法

# 9. 创新点是什么

# 10. 如何用于本专业

# 11. 该方案还存在的问题

# 12. 注释
