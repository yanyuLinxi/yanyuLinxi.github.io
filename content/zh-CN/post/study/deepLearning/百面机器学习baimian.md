---
title: "百面机器学习baimian"
date: 2021-12-06T20:25:47+08:00
tags : [

]
categories : [

]
series : []
aliases : []
draft: false
---

# 为了实习而计划的学习顺序
特征工程
模型评估部分
经典算法部分
非监督学习部分
优化算法部分
采样部分
前向神经网络部分
循环神经网络部分
集成学习部分

注重工程共性问题。其他问题先放放

# 特征工程

1. 归一化:
   1. 线性函数归一化，数据集中时比较适用。
   2. 零均值归一化。
2. 特征编码
   1. 常用的分为序号编码和one-hot编码
   2. 当数据有严格的偏序关系时，建议使用序号编码。就是对数据分类，比如编号为2的类，整体上比编号为1的类要大。这样有助于减少数据带来的噪声。比如19和16相差只有三岁，63和60也相差3岁。但是成年和未成年带来的意义就完全不一样。

# 优化指标

roc曲线相比于pr曲线更加的不受数据集分布的影响。


# 分类和聚类的区别

区别：
1. 从训练目标来看
   1. **分类**是根据一些给定的已知类别标号的样本，训练某种学习机器（即得到某种目标函数），使它能够对未知类别的样本进行分类。这属于supervised learning（监督学习）。
   2. **聚类**指事先并不知道任何样本的类别标号，希望通过某种算法来把一组未知类别的样本划分成若干类别，聚类的时候，我们并不关心某一类是什么，我们需要实现的目标只是把相似的东西聚到一起，这在机器学习中被称作 unsupervised learning （无监督学习）
   3. 分类，**根据目标**来学习特征。
   4. 聚类根据**数据来训练**。组内的对象相互之间时相似的（相关的），而不同组中的对象是不同的（不相关的）。组内的相似性越大，组间差别越大，聚类就越好。
2. 从数据来看
   1. **分类**知道目标类，讲记录分到具体的类
   2. **聚类**没有训练条件下将样本划分到若干类
   3. **分类**对数据要求没那么高，尤其是深度学习。可以学习特征的表达。
   4. **聚类**对特征要求很高。

# 熵函数
各种熵
https://zhuanlan.zhihu.com/p/35423404

自己读一下的话，信息熵和交叉熵是差不多的公式。\sum p log p。
只不过交叉熵的时候。后面的p是预测的概率分布。所以是\sum p log q.


分类算法：
K近邻（KNN）
决策树
朴素贝叶斯
逻辑回归
支持向量机
随机森林

聚类算法：
K均值（K-means）
DBSCAN
DPEAK
Mediods
Canopy