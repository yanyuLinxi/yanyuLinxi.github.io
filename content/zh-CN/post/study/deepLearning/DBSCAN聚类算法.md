---
title: "DBSCAN聚类算法"
date: 2022-03-06T11:13:48+08:00
tags : [

]
categories : [

]
series : []
aliases : []
draft: false
---

# DBSCAN
1. 定义核心点，获取所有核心点
   1. 对于每一个点画一个圈，当周围圈中点的个数大于定义的值的个数，将其设置为核心点。

2. 从随机选择的一个核心点出发，建立一个簇，将核心点周围圈中的核心点加入到簇中
3. 将与核心点接触的非核心点加入到簇中。不能使用非核心点进行扩充。

公式化描述：
1. 初始化核心点对象为空寂。簇个数为k=0，
2. 对于所有的样本，找出核心点：
   1. 通过距离度量的方式，找到样本x_j的ϵ-邻域子样本集N(x_j)
      1. 对于xj∈D，其ϵ-邻域包含样本集D中与xj的距离不大于ϵ的子样本集
   2. 子样本个数大于等于最小的Minpts， 将样本xj加入核心对象样本集合
      1. MinPts描述了某一样本的距离为ϵ的邻域中样本个数的阈值。
3. 随机选择一个核心点，初始化当前核心队列，将邻域内所有的核心点加入到当前核心队列中。
4. 然后将所有核心点队列邻域中的非核心点加入簇中。并将核心队列加入到簇中。构建完一个簇。
5. 重复上述步骤，没有加入到任何簇中的点是异常点。

与传统的K-Means算法相比，DBSCAN最大的不同就是不需要输入类别数k，当然它最大的优势是可以发现任意形状的聚类簇，而不是像K-Means，一般仅仅使用于凸的样本集聚类。同时它在聚类的同时还可以找出异常点。

那么我们什么时候需要用DBSCAN来聚类呢？一般来说，如果数据集是稠密的，并且数据集不是凸的，那么用DBSCAN会比K-Means聚类效果好很多。

## 轮廓系数

当文本类别未知时，可以选择轮廓系数作为聚类性能的评估指标。

轮廓系数取值范围为[-1,1]，取值越接近1则说明聚类性能越好，相反，取值越接近-1则说明聚类性能越差。

a：某个样本与其所在簇内其他样本的平均距离
b：某个样本与其他簇样本的平均距离

针对某个样本的轮廓系数$s = \frac{b-a}{max(a,b)}$
聚类总的轮廓系数等于所有样本的罗阔系数的均值。

### 评估
轮廓系数越接近于1，效果越好。越接近于0，说明类内和类别之间的距离差不多，分界不明显。越接近-1说明类别之间越相似，类别内部反而不相似。

## 面试题
1. 优缺点：
   1. 优点：
      1. 可以对任意形状的稠密数据集进行聚类，相对的，K-Means之类的聚类算法一般只适用于凸数据集。
      2. 可以在聚类的同时发现异常点，对数据集中的异常点不敏感。
      3. 聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。
      4. 总结：对任意的稠密数据进行聚类，比K-means适用更广泛。聚类的时候可以发现异常点。初始值影响不大。（K-means三个缺点，k值难以确定，初始化影响大，异常值影响大)
   2. 缺点
      1. 如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。
      2. 调参相对于传统的K-Means之类的聚类算法稍复杂，主要需要对距离阈值ϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响。
      3. 总结：密度算法当密度不均匀时效果差。调参复杂。