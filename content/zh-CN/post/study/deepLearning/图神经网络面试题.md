---
title: "图神经网络面试题"
date: 2022-03-13T21:10:52+08:00
tags : [

]
categories : [

]
series : []
aliases : []
draft: false
---

# GCN

# GraphSage

GraphSAGE(Graph SAmple and aggreGatE)框架，通过训练聚合节点邻居的函数（卷积层），使GCN扩展成归纳学习任务，对未知节点起到泛化作用。

每次只计算一跳邻居特征，然后通过递归得获得k跳内的邻居信息，极大减少计算复杂度

## 前向传播
1. 先对邻居随机采样，降低计算复杂度（图中一跳邻居采样数=3，二跳邻居采样数=5）
2. 生成目标节点emebedding：先聚合2跳邻居特征，生成一跳邻居embedding，再聚合一跳邻居embedding，生成目标节点embedding，从而获得二跳邻居信息。（后面具体会讲）。
3. 将embedding作为全连接层的输入，预测目标节点的标签。

## 聚合函数
聚合邻居信息的时候可以使用不同的聚合函数
1. 平均聚合：先对邻居embedding中每个维度取平均，然后与目标节点embedding拼接后进行非线性转换。
2. 归纳式聚合：直接对目标节点和所有邻居emebdding中每个维度取平均（替换伪代码中第5、6行），后再非线性转换：
3. LSTM聚合：LSTM函数不符合“排序不变量”的性质，需要先对邻居随机排序，然后将随机的邻居序列embedding作为LSTM输入。
4. Pooling聚合器:先对每个邻居节点上一层embedding进行非线性转换（等价单个全连接层，每一维度代表在某方面的表示（如信用情况）），再按维度应用 max/mean pooling，捕获邻居集上在某方面的突出的／综合的表现 以此表示目标节点embedding。

## 无监督和有监督损失设定
1. 基于图的无监督损失：希望节点u与“邻居”v的embedding也相似（对应公式第一项），而与“没有交集”的节点 V_n 不相似
2. 有监督损失：无监督损失函数的设定来学习节点embedding 可以供下游多个任务使用，若仅使用在特定某个任务上，则可以替代上述损失函数符合特定任务目标，如交叉熵。

## 实际运行
对每个节点进行步长为5的50次随机游走