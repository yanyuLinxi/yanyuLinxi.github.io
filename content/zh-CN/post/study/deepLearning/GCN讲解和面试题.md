---
title: "GCN讲解和面试题"
date: 2022-03-04T22:08:25+08:00
tags : [

]
categories : [

]
series : []
aliases : []
draft: false
---

# GCN图卷积神经网络

## 基于谱的图卷积神经网络
https://www.bilibili.com/video/BV1Vw411R7Fj
https://ml-researcher.github.io/file/gcn.pdf

https://www.cnblogs.com/siviltaram/p/graph_neural_network_1.html
数学公式推导，讲的特别好。

## 卷积是什么
1. 卷积：聚合相邻元素的信息。它相当于滤波器的作用，不同的卷积核保留了部分的信息，舍去了部分的信息。
2. 图卷积就是需要聚合周围邻居节点的加权信息。
3. 由于拓扑图中每个顶点的邻居数量不同。无法找到一个通用的卷积核来进行卷积运算。所以我们的办法是，使用傅里叶变换，对空间域进行转换。转换后的空间域可以执行卷积操作。
   1. 具体的：拉普拉斯矩阵是一个很好的矩阵，由于它是是对称矩阵，它可以被分解为$L=D-A=U\wedge U^T$，$Lx=[\sum(x_1-x_j),\sum(x_2-x_j)]$表示了聚合的含义。
   2. 谱领域的卷积就是对图做傅里叶变换，转换到一个新域，然后对特征值进行操作，在转换回现在的域。
   3. 但是对拉普拉斯矩阵的特征分解复杂度太高。
   4. 所以我们限制核函数（对特征值操作的函数）为多项式$w_1x_1+w_2x_2$等等。这样$Ug(\wedge)U^T=g(U\wedge U^T)$,为了避免梯度消失、梯度爆炸。我们采用切比雪夫不等式的前两项$T(x)=2T_1(x)-T_0(x)$,$T_1(x)=x,T_0(x)=1$,切比雪夫的性质$T_n(cos \theta)=n cos \theta$所以值不会爆炸，而会被限制在这个区间范围内。但是这要求定义域是[-1,1]
   5. 而$L_{sym}=D^{-\frac{1}{2}}LD^{-\frac{1}{2}}$的特征值的域是[0,2]，所以我们使用$L_{sym}-I$作为我们的傅里叶变换的矩阵。
   6. 最后整体的公式就是$f(A)=f(D^{-\frac{1}{2}}(D-A)D^{-\frac{1}{2}}-I)=f(D^{-\frac{1}{2}}AD^{-\frac{1}{2}}x), x=H^{l-1}w$

## 基于空间的图卷积神经网络
1. 基于最简单的空域的思想，聚合邻居节点，然后更新当前节点的信息。

## 消息传递神经网络

三个步骤：
1. 从邻居当中聚合信息（如何聚合）
2. 使用聚合信息更新当前节点（如何更新）
3. 获取整张图的信息（如何获取）图的输出
   1. 需要满足输入顺序不影响最终结果。

