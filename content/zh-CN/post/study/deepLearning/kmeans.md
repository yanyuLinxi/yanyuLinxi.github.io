---
title: "Kmeans"
date: 2021-12-11T17:08:12+08:00
tags : [

]
categories : [

]
series : []
aliases : []
draft: false
---

# 聚类算法（clustering Algorithms）介绍
聚类是一种无监督学习—对大量未知标注的数据集，按数据的内在相似性将数据集划分为多个类别，使类别内的数据相似度较大而类别间的数据相似度较小。

聚类算法可以分为**原型聚类**（k均值算法（K-means）、**学习向量量化**、（Learning Vector Quantization -LVQ）、**高斯混合聚类**（Mixture-of-Gaussian），**密度聚类**（DBSCAN），**层次聚类**（AGNES）等。

原型聚类：，就是通过参考一个模板向量或模板分布的方式来完成聚类的过程

# kmeans原理详解

kmean步骤：

1. 随机初始化k个簇中心坐标
   1. 或者随机选k个点做为簇坐标。
2. 计算数据集内所有点到k个簇中心的距离，并将数据点划分近最近的簇
3. 更新簇中心坐标为当前簇内节点的坐标平均值
4. 重复2、3步骤直到簇中心坐标不再改变（收敛了）

# 改进

| 缺点                                                         | 改进      | 描述                                     |
| :----------------------------------------------------------- | :-------- | :--------------------------------------- |
| k值的确定                                                    | ISODATA   | 当属于某个簇的样本数过少时把这个簇去除， 当属于某个簇的样本数过多、分散程度较大时把这个簇分为两个子簇 |
| 对奇异点敏感                                                 | k-median  | 中位数代替平均值作为簇中心               |
| 只能找到球状群                                               | GMM       | 以高斯分布考虑簇内数据点的分布           |
| 分群结果不稳定                                               | K-means++ | 初始的聚类中心之间的相互距离要尽可能的远 |


# k值的选取

簇内误差和：簇内每个样本到簇中心的距离的平方和，一定程度代表了聚类效果的好坏。

绘制K和合簇内误差和的图，将拐点确定为k。

K-means算法要求事先知道数据集能分为几群，主要有两种方法定义k。

1. 手肘法：通过绘制k和损失函数的关系图，选拐点处的k值。

2. 经验选取人工据经验先定几个k，多次随机初始化中心选经验上最适合的。


通常都是以经验选取，因为实际操作中拐点不明显，且手肘法效率不高。

# 注意

## K-means算法中初始点的选择对最终结果的影响
K-means选择的初始点不同获得的最终分类结果也可能不同，随机选择的中心会导致K-means陷入局部最优解。

## 为什么在计算K-means之前要将数据点在各维度上归一化
确保各个维度量纲相同。

## K-means不适用哪些数据
**数据特征极强相关的数据集**，因为会很难收敛（损失函数是非凸函数），一般要用kernal K-means，将数据点映射到更高维度再分群。

数据集可分出来的**簇密度不一**，或有很多离群值（outliers），这时候考虑使用密度聚类。

## K-means 中常用的距离度量
K-means中比较常用的距离度量是欧几里得距离和余弦相似度。

## K-means是否会一直陷入选择质心的循环停不下来（为什么迭代次数后会收敛）？
从K-means的第三步我们可以看出，每回迭代都会用簇内点的平均值去更新簇中心，所以最终簇内的平方误差和（SSE, sum of squared error）一定最小

# 聚类和分类区别
产生的结果相同（将数据进行分类）
聚类事先没有给出标签（无监督学习）

# 如何对K-means聚类效果进行评估
回到聚类的定义，我们希望得到**簇内数据相似度尽可能地大**，而**簇间相似度**尽可能地小。

聚类算法几乎没有统一的评估指标，可能还需要根据聚类目标想评估方式

这个自己记得不是很清楚。
主要记得 
簇内平方和。（每个点和质心的欧几里得距离平方平均）
簇间平方和。（质心的平方平均距离）

# 面试题

1. 优缺点
   1. 优点：
      1. 实现容易，收敛速度快
      2. 聚类效果优良
   2. 缺点：
      1. k难以确定，依赖于初始值的选择。
      2. 对噪音和异常点比较的敏感，聚出来的类密度相差很大。